{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNq4LTAEy0dK3CzyE6Nw/8b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SantiagoGlezCh7/basedatos_SantiagoGlezCh424096368/blob/Proyectos/ProyectoFinal21_marzo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dcDBUo62wPp5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "f59e4baf-eb59-4cca-adb6-12ecd5c18c35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faker in /usr/local/lib/python3.11/dist-packages (37.3.0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from faker) (2025.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install faker\n",
        "\n",
        "!pip install pandas\n",
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from faker import Faker\n",
        "import random\n",
        "import os\n",
        "from datetime import datetime, timedelta"
      ],
      "metadata": {
        "id": "wjXJVenrw88E"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***CAPA BRONCE DATOS CRUDOS ***"
      ],
      "metadata": {
        "id": "_eB0pp_SIbsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('bronze', exist_ok=True)\n",
        "fake = Faker()\n"
      ],
      "metadata": {
        "id": "8H4JwejmxA3L"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_stores_target = 3000\n",
        "print(f\"Creando df_stores con {num_stores_target} tiendas...\")\n",
        "nombres_tiendas = [fake.company() + ' Bakery ' + str(i) for i in range(num_stores_target)]\n",
        "ciudades_tiendas = [fake.city() for _ in range(num_stores_target)]\n",
        "def generate_stores_data(num_stores):\n",
        "\n",
        "    \"\"\"Genera datos simulados para la dimensión de tiendas.\"\"\"\n",
        "    print(f\"Generando datos para {num_stores} tiendas...\")\n",
        "    fake = Faker('es_ES') # Datos en español\n",
        "    stores_list = []\n",
        "    # Ciudades de ejemplo en español para dar variedad\n",
        "    cities = ['Madrid', 'Barcelona', 'Valencia', 'Sevilla', 'Zaragoza',\n",
        "              'Málaga', 'Murcia', 'Palma', 'Las Palmas de Gran Canaria',\n",
        "              'Bilbao', 'Alicante', 'Córdoba', 'Valladolid', 'Vigo',\n",
        "              'León', 'Salamanca', 'Granada', 'Toledo', 'Santiago de Compostela',\n",
        "              'Santander', 'Gijón', 'Oviedo', 'Pamplona', 'Logroño', 'Cádiz',\n",
        "              'Burgos', 'Albacete', 'Huelva', 'Jaén', 'Lérida', 'Girona',\n",
        "              'Tarragona', 'Cáceres', 'Badajoz', 'Soria', 'Cuenca', 'Ávila',\n",
        "              'Segovia', 'Teruel', 'Huesca', 'Palencia', 'Zamora', 'Orense',\n",
        "              'Lugo', 'Pontevedra', 'Ceuta', 'Melilla', 'San Sebastián', 'Vitoria-Gasteiz'\n",
        "             ]\n",
        "    regions = ['Centro', 'Norte', 'Este', 'Sur', 'Canarias', 'Noroeste', 'Levante', 'Andalucía', 'Aragón', 'Castilla y León', 'Cataluña']\n",
        "\n",
        "    for i in range(num_stores):\n",
        "        store_city = random.choice(cities)\n",
        "        stores_list.append({\n",
        "            'store_id': range(1, num_stores_target + 1),\n",
        "            'store_name': f\"Tienda {i + 1} - {store_city}\",\n",
        "            'city': store_city,\n",
        "            'region': random.choice(regions),\n",
        "            'opening_date': fake.date_between(start_date='-10y', end_date='today')\n",
        "        })\n",
        "    df_stores = pd.DataFrame(stores_list)\n",
        "    print(f\"Datos de tiendas generados: {len(df_stores)} registros.\")\n",
        "    return df_stores\n",
        "# Definir el número de productos que quieres generar\n",
        "NUM_PRODUCTOS_OBJETIVO = 200 # Basado en tu solicitud de 200 productos\n",
        "\n",
        "def generate_products_data_custom(num_products_objective, fake_instance):\n",
        "    \"\"\"\n",
        "    Genera datos para la dimensión de productos usando la lógica proporcionada,\n",
        "    asegurando el número de productos especificado con clasificación de pan y otros.\n",
        "    Los nombres de las columnas ya están estandarizados para el pipeline.\n",
        "    \"\"\"\n",
        "    print(f\"Generando datos para DimProducto ({num_products_objective} productos, incluyendo clasificación de pan)...\")\n",
        "    productos_data_list = []\n",
        "\n",
        "    # Clasificaciones de Pan\n",
        "    tipos_harina = ['Trigo', 'Centeno', 'Espelta', 'Maíz', 'Germinado', 'Mixta', 'Sin Gluten']\n",
        "    sabores_aditivos = ['Básico', 'Con Semillas', 'De Ajo', 'Dulce', 'Integral', 'Fermentado', 'Crocante', 'Amargo']\n",
        "    categorias_pan = ['Panadería Artesanal', 'Pan Dulce', 'Bollos', 'Panes Especiales', 'Pan Integral', 'Pan de Molde']\n",
        "    categorias_no_pan = ['Bebida Caliente', 'Bebida Fría', 'Repostería', 'Bocadillo Salado', 'Postre', 'Salado']\n",
        "\n",
        "    # Nombres base para los productos (mezclando pan y otros genéricos)\n",
        "    nombres_pan_base = [\n",
        "        'Pan de Campo', 'Baguette', 'Ciabatta', 'Focaccia', 'Pan de Centeno Clásico',\n",
        "        'Pan de Maíz', 'Pan de Espelta', 'Pan Germinado Vital', 'Pan Multicereal',\n",
        "        'Pan Integral Casero', 'Pan Dulce de Naranja', 'Bollos de Leche', 'Croissant',\n",
        "        'Pan de Ajo Rústico', 'Pan con Semillas de Chía', 'Pan de Masa Madre',\n",
        "        'Panini', 'Brioche', 'Muffin de Pan', 'Pan de Coco', 'Pan Chapata', 'Pan de Pita',\n",
        "        'Pan de Hamburguesa', 'Pan de Hot Dog', 'Pan de Avena', 'Pan de Calabaza',\n",
        "        'Pan de Zanahoria', 'Pan de Cebolla', 'Pan de Aceitunas', 'Pan de Tomate Seco'\n",
        "    ]\n",
        "    # Nombres base para otros productos\n",
        "    nombres_otros_base = [\n",
        "        'Café Americano', 'Latte Macchiato', 'Té Verde', 'Jugo de Naranja', 'Agua Mineral',\n",
        "        'Galleta de Avena', 'Muffin de Arándanos', 'Tarta de Manzana', 'Brownie de Chocolate',\n",
        "        'Sándwich de Jamón y Queso', 'Ensalada César', 'Wrap de Pollo', 'Chips de Patata',\n",
        "        'Donut Glaseado', 'Magdalena', 'Bocadillo de Atún', 'Zumo de frutas', 'Refresco de cola',\n",
        "        'Cerveza artesanal', 'Vino tinto', 'Agua con gas', 'Té helado', 'Chocolate caliente',\n",
        "        'Crepa de Nutella', 'Pastel de chocolate', 'Flan casero', 'Helado de vainilla',\n",
        "        'Barrita energética', 'Yogur griego', 'Cereal integral', 'Sopa de verduras',\n",
        "        'Pizza personal', 'Empanada de carne', 'Quiche de espinacas', 'Taco de cochinita',\n",
        "        'Nachos con queso', 'Burrito de pollo', 'Enchiladas suizas', 'Guacamole con totopos',\n",
        "        'Gelatina de fresa', 'Arroz con leche', 'Churros con chocolate', 'Buñuelos',\n",
        "        'Paleta de hielo', 'Fruta fresca', 'Smoothie verde', 'Ensalada de frutas',\n",
        "        'Panqueques con miel', 'Waffles con crema', 'Huevo revuelto', 'Omelette de queso',\n",
        "        'Tostada de aguacate', 'Cereal con leche', 'Sopa de tortilla', 'Crema de champiñones'\n",
        "    ]\n",
        "\n",
        "    # Combinamos y extendemos los nombres si NUM_PRODUCTOS_OBJETIVO lo requiere,\n",
        "    # para tener suficientes nombres únicos\n",
        "    all_base_names = nombres_pan_base + nombres_otros_base\n",
        "    extended_names = list(all_base_names)\n",
        "    while len(extended_names) < num_products_objective:\n",
        "        extended_names.append(fake_instance.unique.word().capitalize() + f' Gen {len(extended_names)}')\n",
        "    random.shuffle(extended_names) # Mezclamos para no tener solo pan al principio\n",
        "\n",
        "    # Generar datos de productos\n",
        "    for i in range(num_products_objective):\n",
        "        nombre_producto = extended_names[i]\n",
        "        precio_base = round(np.random.uniform(1.0, 50.0), 2)\n",
        "        marca = fake_instance.company()\n",
        "\n",
        "        # Lógica para identificar panes (más robusta)\n",
        "        is_bread = False\n",
        "        if any(word in nombre_producto.lower() for word in ['pan', 'baguette', 'ciabatta', 'focaccia', 'brioche', 'bollo', 'croissant', 'muffin', 'chapata', 'pita', 'hamburguesa', 'hot dog', 'avena', 'calabaza', 'zanahoria', 'cebolla', 'aceitunas', 'tomate seco', 'multicereal', 'integral', 'centeno', 'espelta', 'maíz', 'germinad']):\n",
        "            is_bread = True\n",
        "\n",
        "        # Clasificar y asignar detalles de pan/no pan\n",
        "        if is_bread:\n",
        "            categoria_producto = random.choice(categorias_pan)\n",
        "            tipo_harina_pan = random.choice(tipos_harina)\n",
        "            sabor_aditivo_pan = random.choice(sabores_aditivos)\n",
        "        else:\n",
        "            categoria_producto = random.choice(categorias_no_pan)\n",
        "            tipo_harina_pan = 'No Aplica'\n",
        "            sabor_aditivo_pan = 'No Aplica'\n",
        "\n",
        "        productos_data_list.append({\n",
        "            'product_id': i + 1,\n",
        "            'product_name': nombre_producto,\n",
        "            'category': categoria_producto,\n",
        "            'brand': marca,\n",
        "            'price': precio_base,\n",
        "            'flour_type_bread': tipo_harina_pan,\n",
        "            'additive_flavor_bread': sabor_aditivo_pan\n",
        "        })\n",
        "    df_products = pd.DataFrame(productos_data_list)\n",
        "    print(f\"Datos de productos generados: {len(df_products)} registros.\")\n",
        "    return df_products"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvWlRuz252ZW",
        "outputId": "8e90f6d4-a10c-48d8-fdd1-e912ab064ee3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creando df_stores con 3000 tiendas...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_stores = generate_stores_data(num_stores_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOaf7vEgE5V8",
        "outputId": "6334e07a-cd51-48ba-f617-820392e0612d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generando datos para 3000 tiendas...\n",
            "Datos de tiendas generados: 3000 registros.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_bakery = pd.read_csv('Bakery.csv')\n"
      ],
      "metadata": {
        "id": "uewVTZqsxeDM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPrimeras 5 filas:\")\n",
        "print(df_bakery.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "alvWNoTk5XuB",
        "outputId": "daed11e1-9543-4083-fcbf-e1e909a15cc8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Primeras 5 filas:\n",
            "   TransactionNo          Items             DateTime  Daypart  DayType\n",
            "0              1          Bread  2016-10-30 09:58:11  Morning  Weekend\n",
            "1              2   Scandinavian  2016-10-30 10:05:34  Morning  Weekend\n",
            "2              2   Scandinavian  2016-10-30 10:05:34  Morning  Weekend\n",
            "3              3  Hot chocolate  2016-10-30 10:07:57  Morning  Weekend\n",
            "4              3            Jam  2016-10-30 10:07:57  Morning  Weekend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Obtener una lista de los IDs de tienda disponibles de df_stores\n",
        "ids_tiendas_disponibles = df_stores['store_id'].tolist()\n"
      ],
      "metadata": {
        "id": "grS42XK27Vqb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generar una lista de IDs de tienda aleatorios del tamaño de df_bakery\n",
        "# Usamos random.choices para permitir repeticiones\n",
        "tiendas_aleatorias = random.choices(ids_tiendas_disponibles, k=len(df_bakery))"
      ],
      "metadata": {
        "id": "qRTcDW5U827r"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Asignar esta lista como una nueva columna en df_bakery\n",
        "df_bakery['ID_Tienda_Aleatoria'] = tiendas_aleatorias"
      ],
      "metadata": {
        "id": "ydJ0Emzx9AqX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nDataFrame df_bakery con la nueva columna 'ID_Tienda_Aleatoria':\")\n",
        "print(df_bakery.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9YKoWhiu9IjX",
        "outputId": "26ec1e03-9cca-4fa6-bf3c-0bf5daec440f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame df_bakery con la nueva columna 'ID_Tienda_Aleatoria':\n",
            "   TransactionNo          Items             DateTime  Daypart  DayType  \\\n",
            "0              1          Bread  2016-10-30 09:58:11  Morning  Weekend   \n",
            "1              2   Scandinavian  2016-10-30 10:05:34  Morning  Weekend   \n",
            "2              2   Scandinavian  2016-10-30 10:05:34  Morning  Weekend   \n",
            "3              3  Hot chocolate  2016-10-30 10:07:57  Morning  Weekend   \n",
            "4              3            Jam  2016-10-30 10:07:57  Morning  Weekend   \n",
            "\n",
            "                                 ID_Tienda_Aleatoria  \n",
            "0  (1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...  \n",
            "1  (1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...  \n",
            "2  (1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...  \n",
            "3  (1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...  \n",
            "4  (1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nColumnas en df_bakery:\", df_bakery.columns.tolist())\n",
        "print(\"Columnas en df_stores:\", df_stores.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qzuVEl4Y9_SQ",
        "outputId": "f602d907-62ff-4d75-ed9c-1d64333a61f0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Columnas en df_bakery: ['TransactionNo', 'Items', 'DateTime', 'Daypart', 'DayType', 'ID_Tienda_Aleatoria']\n",
            "Columnas en df_stores: ['store_id', 'store_name', 'city', 'region', 'opening_date']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizar el merge (join)\n",
        "# left_on: la columna en df_bakery\n",
        "# right_on: la columna en df_stores\n",
        "# how='left': Mantiene todas las filas de df_bakery\n",
        "df_final = pd.merge(df_bakery, df_stores,\n",
        "                    left_on='ID_Tienda_Aleatoria',\n",
        "                    right_on='store_id',\n",
        "                    how='left')\n",
        "\n",
        "# 1. Columna 'Cantidad' (Qty)\n",
        "# Para cada fila (que representa un item en una transacción),\n",
        "# asignamos una cantidad aleatoria (ej. entre 1 y 5 unidades por item).\n",
        "df_final['Cantidad'] = np.random.randint(1, 6, size=len(df_final)) # Genera enteros entre 1 y 5\n",
        "\n",
        "# 2. Columna 'Precio_Unitario'\n",
        "# Asignaremos precios unitarios aleatorios.\n",
        "# Los precios dependerán del tipo de producto. Podemos usar un rango general\n",
        "# o, para mayor realismo, un diccionario de precios base por producto.\n",
        "\n",
        "# Para simplificar y mantener la aleatoriedad, un rango general:\n",
        "df_final['Precio_Unitario'] = np.round(np.random.uniform(1.0, 25.0, size=len(df_final)), 2)\n",
        "# Nota: Esto asigna un precio unitario aleatorio a CADA INSTANCIA del producto,\n",
        "# incluso si es el mismo producto en diferentes transacciones.\n",
        "# Si quisieras un precio fijo por tipo de 'Items', sería diferente.\n",
        "\n",
        "# Ejemplo de precios fijos por producto (más realista, pero más complejo si hay muchos productos)\n",
        "# precios_base = {\n",
        "#     'Bread': 2.50, 'Scandinavian': 3.00, 'Hot chocolate': 4.50, 'Jam': 3.50,\n",
        "#     'Coffee': 3.00, 'Tea': 2.80, 'Pastry': 2.00, 'Muffin': 2.20, 'Cookies': 1.80,\n",
        "#     'Cake': 20.00, 'Scone': 2.00, 'Donut': 2.00\n",
        "# }\n",
        "# # Función para obtener el precio base y añadir un poco de aleatoriedad (ej. +- 10%)\n",
        "# def get_random_price(item):\n",
        "#     base = precios_base.get(item, 5.00) # 5.00 es un precio por defecto si no lo encuentra\n",
        "#     return round(base * random.uniform(0.9, 1.1), 2)\n",
        "# df_final['Precio_Unitario'] = df_final['Items'].apply(get_random_price)\n",
        "\n",
        "\n",
        "# 3. Columna 'Total_Producto' (Cantidad * Precio_Unitario)\n",
        "\n",
        "df_final['Total_Producto'] = df_final['Cantidad'] * df_final['Precio_Unitario']\n",
        "\n",
        "print(\"\\nDataFrame final con 'Cantidad', 'Precio_Unitario' y 'Total_Producto' añadidos:\")\n",
        "print(df_final.head(10)) # Muestra más filas para ver mejor los nuevos datos\n",
        "\n",
        "# Información para verificar los nuevos tipos de datos\n",
        "print(\"\\nInformación del DataFrame final con las nuevas columnas:\")\n",
        "df_final.info()\n",
        "\n",
        "print(\"\\nDataFrame final después de juntar (merge) los datos de la tienda:\")\n",
        "print(df_final.head())\n",
        "\n",
        "print(\"\\nInformación del DataFrame final para verificar tipos y nulos:\")\n",
        "df_final.info()"
      ],
      "metadata": {
        "id": "Eh_-F0Dc9mKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CREACIÓN DE df_bakery (para ~1 millón de filas de ventas) ---\n",
        "num_rows_target = 1_000_000 # Un millón de filas de ventas (cada fila es un ítem vendido)\n",
        "print(f\"Creando df_bakery con {num_rows_target} filas de ventas...\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WdY9SbH-Zvv",
        "outputId": "ed1173d3-8e85-4f59-d46c-eccadc520ae5"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creando df_bakery con 1000000 filas de ventas...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Para 200 productos únicos\n",
        "num_products_target = 200\n",
        "productos_unicos = [fake.word().capitalize() + str(i) for i in range(num_products_target)]\n",
        "\n",
        "# Generar datos para df_bakery\n",
        "# Generaremos TransactionNo de forma que tengamos aproximadamente 1 millón de filas de ítems\n",
        "# Si cada transacción tiene en promedio 3 ítems, necesitaríamos ~333,333 transacciones únicas.\n",
        "# Para simplificar y asegurar 1M de filas, haremos que cada fila represente un \"item_venta\" único,\n",
        "# y TransactionNo se puede repetir para simular múltiples ítems por transacción.\n",
        "# La forma más directa de obtener 1M de filas es generar 1M de TransactionNo y luego items, etc.\n",
        "\n",
        "# IDs de transacción (pueden repetirse para simular múltiples ítems por transacción)\n",
        "# Asignaremos TransactionNo en bloques para simular transacciones con varios ítems.\n",
        "# Por ejemplo, cada 3 ítems podrían ser la misma transacción.\n",
        "items_per_transaction_avg = 3 # Puedes ajustar este promedio\n",
        "num_transactions_unique = num_rows_target // items_per_transaction_avg\n",
        "\n",
        "transaction_nos = np.repeat(np.arange(1, num_transactions_unique + 1), items_per_transaction_avg)[:num_rows_target]\n",
        "# Aseguramos que la longitud sea exactamente num_rows_target\n",
        "if len(transaction_nos) < num_rows_target:\n",
        "    transaction_nos = np.concatenate((transaction_nos, np.arange(num_transactions_unique + 1, num_transactions_unique + 1 + (num_rows_target - len(transaction_nos)))))\n",
        "elif len(transaction_nos) > num_rows_target:\n",
        "    transaction_nos = transaction_nos[:num_rows_target]\n",
        "\n",
        "# Otros datos para df_bakery\n",
        "items = random.choices(productos_unicos, k=num_rows_target)\n",
        "prices = np.round(np.random.uniform(1.0, 50.0, size=num_rows_target), 2)\n",
        "quantities_sold = np.random.randint(1, 10, size=num_rows_target)\n",
        "\n",
        "# Generar fechas aleatorias dentro de un rango (ej. los últimos 2 años)\n",
        "start_date = pd.to_datetime('2023-01-01')\n",
        "end_date = pd.to_datetime('2025-05-20') # Fecha actual\n",
        "# Generar timestamps aleatorios\n",
        "random_dates_numeric = np.random.uniform(start_date.timestamp(), end_date.timestamp(), size=num_rows_target)\n",
        "dates = pd.to_datetime(random_dates_numeric, unit='s')\n"
      ],
      "metadata": {
        "id": "GE2gV3b6-Zfn"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"df_bakery creado con un millón de filas.\")\n",
        "print(df_bakery.head())\n",
        "print(f\"Shape de df_bakery: {df_bakery.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pc6heCjuEZXZ",
        "outputId": "b069886e-974e-4aed-c84d-99d2d8c8340c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_bakery creado con un millón de filas.\n",
            "   TransactionNo          Items             DateTime  Daypart  DayType  \\\n",
            "0              1          Bread  2016-10-30 09:58:11  Morning  Weekend   \n",
            "1              2   Scandinavian  2016-10-30 10:05:34  Morning  Weekend   \n",
            "2              2   Scandinavian  2016-10-30 10:05:34  Morning  Weekend   \n",
            "3              3  Hot chocolate  2016-10-30 10:07:57  Morning  Weekend   \n",
            "4              3            Jam  2016-10-30 10:07:57  Morning  Weekend   \n",
            "\n",
            "   ID_Tienda_Aleatoria  \n",
            "0                  580  \n",
            "1                  335  \n",
            "2                  642  \n",
            "3                  790  \n",
            "4                  361  \n",
            "Shape de df_bakery: (20507, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nDataFrame 'df_final' (con info de tiendas) creado y listo para añadir detalles de venta.\")\n",
        "print(df_final.head())\n",
        "print(f\"Shape de df_final después del primer merge: {df_final.shape}\")\n",
        "df_final.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjsgHlIBE6re",
        "outputId": "8001f739-9e39-426b-fe6f-94cbe14e1b66"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame 'df_final' (con info de tiendas) creado y listo para añadir detalles de venta.\n",
            "   TransactionNo          Items             DateTime  Daypart  DayType  \\\n",
            "0              1          Bread  2016-10-30 09:58:11  Morning  Weekend   \n",
            "1              2   Scandinavian  2016-10-30 10:05:34  Morning  Weekend   \n",
            "2              2   Scandinavian  2016-10-30 10:05:34  Morning  Weekend   \n",
            "3              3  Hot chocolate  2016-10-30 10:07:57  Morning  Weekend   \n",
            "4              3            Jam  2016-10-30 10:07:57  Morning  Weekend   \n",
            "\n",
            "   ID_Tienda_Aleatoria  store_id           store_name    city  \\\n",
            "0                  160       160    Tienda 160 - Jaén    Jaén   \n",
            "1                  153       153    Tienda 153 - Jaén    Jaén   \n",
            "2                  381       381  Tienda 381 - Murcia  Murcia   \n",
            "3                    2         2    Tienda 2 - Burgos  Burgos   \n",
            "4                  536       536    Tienda 536 - León    León   \n",
            "\n",
            "            region opening_date  Cantidad  Precio_Unitario  Total_Producto  \n",
            "0          Levante   2020-05-18         1            17.77           17.77  \n",
            "1           Aragón   2019-09-24         3            11.20           33.60  \n",
            "2  Castilla y León   2023-12-18         4             6.10           24.40  \n",
            "3           Centro   2024-05-02         5             7.84           39.20  \n",
            "4          Levante   2017-02-13         5             1.09            5.45  \n",
            "Shape de df_final después del primer merge: (20507, 14)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20507 entries, 0 to 20506\n",
            "Data columns (total 14 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   TransactionNo        20507 non-null  int64  \n",
            " 1   Items                20507 non-null  object \n",
            " 2   DateTime             20507 non-null  object \n",
            " 3   Daypart              20507 non-null  object \n",
            " 4   DayType              20507 non-null  object \n",
            " 5   ID_Tienda_Aleatoria  20507 non-null  int64  \n",
            " 6   store_id             20507 non-null  int64  \n",
            " 7   store_name           20507 non-null  object \n",
            " 8   city                 20507 non-null  object \n",
            " 9   region               20507 non-null  object \n",
            " 10  opening_date         20507 non-null  object \n",
            " 11  Cantidad             20507 non-null  int64  \n",
            " 12  Precio_Unitario      20507 non-null  float64\n",
            " 13  Total_Producto       20507 non-null  float64\n",
            "dtypes: float64(2), int64(4), object(8)\n",
            "memory usage: 2.2+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_tiendas_unicas = df_stores['store_id'].nunique()\n",
        "print(f\"\\nNúmero de tiendas únicas en df_stores (creadas): {num_tiendas_unicas}\")\n",
        "\n",
        "num_productos_unicos = df_final['Items'].nunique()\n",
        "print(f\"Número de productos únicos en df_final (derivado de df_bakery): {num_productos_unicos}\")\n",
        "\n",
        "num_filas_ventas = df_final.shape[0]\n",
        "print(f\"Número total de filas de ventas (ítems individuales) en df_final: {num_filas_ventas}\")\n",
        "\n",
        "num_transacciones_unicas = df_final['TransactionNo'].nunique()\n",
        "print(f\"Número total de transacciones únicas en df_final: {num_transacciones_unicas}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(\"--- VERIFICACIÓN COMPLETA ---\")\n",
        "print(\"=\"*30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gBfjzEJyFJBy",
        "outputId": "6fbd7855-b8c4-4172-f8ac-4c4dabbe9f75"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Número de tiendas únicas en df_stores (creadas): 1000\n",
            "Número de productos únicos en df_final (derivado de df_bakery): 94\n",
            "Número total de filas de ventas (ítems individuales) en df_final: 20507\n",
            "Número total de transacciones únicas en df_final: 9465\n",
            "\n",
            "==============================\n",
            "--- VERIFICACIÓN COMPLETA ---\n",
            "==============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define el nombre de tu archivo Parquet\n",
        "nombre_archivo = 'bakery_sales_bronze.parquet'\n",
        "full_path = os.path.join('/content/bronze', nombre_archivo)\n",
        "print(full_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZcyF7jLIJHa",
        "outputId": "1e6216b8-e1a6-4cf5-a3f4-6fd06b590dc2"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/bronze/bakery_sales_bronze.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guarda el DataFrame en formato Parquet\n",
        "# index=False es importante para no guardar el índice del DataFrame como una columna\n",
        "df_final.to_parquet(full_path, index=False)\n",
        "\n",
        "print(f\"\\nDataFrame 'df_final' guardado exitosamente en la capa Bronze como: {full_path}\")\n",
        "print(\"Puedes verificarlo en tu Google Drive en esa ruta.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcGNSKqwJwOx",
        "outputId": "0efee75e-0d5e-4555-de2b-cf84d49f68c7"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame 'df_final' guardado exitosamente en la capa Bronze como: /content/bronze/bakery_sales_bronze.parquet\n",
            "Puedes verificarlo en tu Google Drive en esa ruta.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_leido = pd.read_parquet('/content/bronze/bakery_sales_bronze.parquet')\n",
        "\n",
        "print(f\"\\nDataFrame leído de 'bakery_sales_bronze.parquet':\")\n",
        "print(df_leido.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "L7j__YYNPvOz",
        "outputId": "c7c0642b-7595-4cae-a357-2c636835e39f"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame leído de 'bakery_sales_bronze.parquet':\n",
            "   TransactionNo          Items             DateTime  Daypart  DayType  \\\n",
            "0              1          Bread  2016-10-30 09:58:11  Morning  Weekend   \n",
            "1              2   Scandinavian  2016-10-30 10:05:34  Morning  Weekend   \n",
            "2              2   Scandinavian  2016-10-30 10:05:34  Morning  Weekend   \n",
            "3              3  Hot chocolate  2016-10-30 10:07:57  Morning  Weekend   \n",
            "4              3            Jam  2016-10-30 10:07:57  Morning  Weekend   \n",
            "\n",
            "   ID_Tienda_Aleatoria  store_id           store_name    city  \\\n",
            "0                  160       160    Tienda 160 - Jaén    Jaén   \n",
            "1                  153       153    Tienda 153 - Jaén    Jaén   \n",
            "2                  381       381  Tienda 381 - Murcia  Murcia   \n",
            "3                    2         2    Tienda 2 - Burgos  Burgos   \n",
            "4                  536       536    Tienda 536 - León    León   \n",
            "\n",
            "            region opening_date  Cantidad  Precio_Unitario  Total_Producto  \n",
            "0          Levante   2020-05-18         1            17.77           17.77  \n",
            "1           Aragón   2019-09-24         3            11.20           33.60  \n",
            "2  Castilla y León   2023-12-18         4             6.10           24.40  \n",
            "3           Centro   2024-05-02         5             7.84           39.20  \n",
            "4          Levante   2017-02-13         5             1.09            5.45  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***CAPA PLATA DONDE VAN LAS DIMENSIONES ***"
      ],
      "metadata": {
        "id": "JbpZ_Ou_ISZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('plata', exist_ok=True)\n",
        "fake = Faker()\n"
      ],
      "metadata": {
        "id": "OsjOj9ES0sw5"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_leido = pd.read_parquet('/content/bronze/bakery_sales_bronze.parquet')\n",
        "\n",
        "print(f\"\\nDataFrame leído de 'bakery_sales_bronze.parquet':\")\n",
        "\n",
        "\n",
        "print(df_leido.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "udG6OuFPIZDC",
        "outputId": "8c6b54a3-cce2-4233-d531-d56863dafb60"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame leído de 'bakery_sales_bronze.parquet':\n",
            "   TransactionNo          Items             DateTime  Daypart  DayType  \\\n",
            "0              1          Bread  2016-10-30 09:58:11  Morning  Weekend   \n",
            "1              2   Scandinavian  2016-10-30 10:05:34  Morning  Weekend   \n",
            "2              2   Scandinavian  2016-10-30 10:05:34  Morning  Weekend   \n",
            "3              3  Hot chocolate  2016-10-30 10:07:57  Morning  Weekend   \n",
            "4              3            Jam  2016-10-30 10:07:57  Morning  Weekend   \n",
            "\n",
            "   ID_Tienda_Aleatoria  store_id           store_name    city  \\\n",
            "0                  160       160    Tienda 160 - Jaén    Jaén   \n",
            "1                  153       153    Tienda 153 - Jaén    Jaén   \n",
            "2                  381       381  Tienda 381 - Murcia  Murcia   \n",
            "3                    2         2    Tienda 2 - Burgos  Burgos   \n",
            "4                  536       536    Tienda 536 - León    León   \n",
            "\n",
            "            region opening_date  Cantidad  Precio_Unitario  Total_Producto  \n",
            "0          Levante   2020-05-18         1            17.77           17.77  \n",
            "1           Aragón   2019-09-24         3            11.20           33.60  \n",
            "2  Castilla y León   2023-12-18         4             6.10           24.40  \n",
            "3           Centro   2024-05-02         5             7.84           39.20  \n",
            "4          Levante   2017-02-13         5             1.09            5.45  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener la fecha mínima y máxima de tus datos transaccionales.\n",
        "# Asegúrate de que la columna 'DateTime' sea de tipo datetime.\n",
        "# Si df_final['DateTime'] no es datetime, conviértela explícitamente.\n",
        "if not pd.api.types.is_datetime64_any_dtype(df_final['DateTime']):\n",
        "    df_final['DateTime'] = pd.to_datetime(df_final['DateTime'])\n",
        "\n",
        "# Obtener la fecha mínima y máxima de tus datos transaccionales.\n",
        "min_date_data = df_final['DateTime'].min()\n",
        "max_date_data = df_final['DateTime'].max()\n",
        "\n",
        "# Establecer el inicio y fin del rango de la DimFecha.\n",
        "start_date_dim = min_date_data.floor('D')\n",
        "end_date_dim = max_date_data.ceil('D')\n",
        "\n",
        "# Generar el rango completo de fechas, día a día (freq='D')\n",
        "date_range = pd.date_range(start=start_date_dim, end=end_date_dim, freq='D')\n",
        "\n",
        "print(f\"  Fecha mínima en datos: {min_date_data.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"  Fecha máxima en datos: {max_date_data.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"  Rango de DimFecha generado de: {start_date_dim.strftime('%Y-%m-%d')} a {end_date_dim.strftime('%Y-%m-%d')}\")\n",
        "print(f\"  Número de días en el rango: {len(date_range)}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "\n",
        "# --- PASO 2: Crear el DataFrame Base de DimFecha ---\n",
        "print(\"PASO 2: Creando el DataFrame base de DimFecha...\")\n",
        "\n",
        "# Inicializar el DataFrame con la columna 'Fecha_Completa'\n",
        "dim_fecha = pd.DataFrame({'Fecha_Completa': date_range})\n",
        "\n",
        "print(\"  DataFrame base de DimFecha creado con la columna 'Fecha_Completa'.\")\n",
        "print(dim_fecha.head())\n",
        "print(\"-\" * 70)\n",
        "\n",
        "\n",
        "# --- PASO 3: Calcular y Añadir los Atributos Temporales ---\n",
        "print(\"PASO 3: Calculando y añadiendo los atributos temporales a DimFecha...\")\n",
        "\n",
        "# 3.1. Fecha_ID (Clave Primaria): Formato YYYYMMDD (ej. 20240520)\n",
        "# Este formato entero es eficiente para uniones y almacenamiento.\n",
        "dim_fecha['Fecha_ID'] = dim_fecha['Fecha_Completa'].dt.strftime('%Y%m%d').astype(int)\n",
        "print(\"  - 'Fecha_ID' calculada.\")\n",
        "\n",
        "# 3.2. Atributos Básicos de Fecha\n",
        "dim_fecha['Anio'] = dim_fecha['Fecha_Completa'].dt.year\n",
        "dim_fecha['Mes'] = dim_fecha['Fecha_Completa'].dt.month\n",
        "dim_fecha['Dia'] = dim_fecha['Fecha_Completa'].dt.day\n",
        "print(\"  - 'Anio', 'Mes', 'Dia' calculados.\")\n",
        "\n",
        "# 3.3. Nombres de Mes y Día de la Semana\n",
        "dim_fecha['Nombre_Mes'] = dim_fecha['Fecha_Completa'].dt.strftime('%B').str.capitalize() # Nombre completo del mes (ej. 'Mayo')\n",
        "dim_fecha['Nombre_Dia_Semana'] = dim_fecha['Fecha_Completa'].dt.strftime('%A').str.capitalize() # Nombre completo del día de la semana (ej. 'Martes')\n",
        "print(\"  - 'Nombre_Mes', 'Nombre_Dia_Semana' calculados.\")\n",
        "\n",
        "# 3.4. Día de la Semana (Numérico)\n",
        "# .dt.dayofweek devuelve 0 para Lunes y 6 para Domingo. Sumamos 1 para 1=Lunes, 7=Domingo.\n",
        "dim_fecha['Dia_de_la_Semana'] = dim_fecha['Fecha_Completa'].dt.dayofweek + 1\n",
        "print(\"  - 'Dia_de_la_Semana' calculada (1=Lunes, 7=Domingo).\")\n",
        "\n",
        "# 3.5. Semana del Año (ISO 8601)\n",
        "# .isocalendar().week devuelve el número de semana ISO.\n",
        "dim_fecha['Semana_del_Anio'] = dim_fecha['Fecha_Completa'].dt.isocalendar().week.astype(int)\n",
        "print(\"  - 'Semana_del_Anio' calculada.\")\n",
        "\n",
        "# 3.6. Trimestre y Nombre del Trimestre\n",
        "dim_fecha['Trimestre'] = dim_fecha['Fecha_Completa'].dt.quarter\n",
        "dim_fecha['Nombre_Trimestre'] = 'Q' + dim_fecha['Trimestre'].astype(str) + '-' + dim_fecha['Anio'].astype(str)\n",
        "print(\"  - 'Trimestre', 'Nombre_Trimestre' calculados.\")\n",
        "\n",
        "# 3.7. Indicadores Booleanos (Fin de Semana / Día Laboral)\n",
        "# .dt.weekday devuelve 0=Lunes, 1=Martes,..., 4=Viernes, 5=Sábado, 6=Domingo\n",
        "dim_fecha['Es_Fin_De_Semana'] = dim_fecha['Fecha_Completa'].dt.weekday.isin([5, 6])\n",
        "dim_fecha['Es_Dia_Laboral'] = ~dim_fecha['Es_Fin_De_Semana'] # Es lo opuesto a 'Es_Fin_De_Semana'\n",
        "print(\"  - 'Es_Fin_De_Semana', 'Es_Dia_Laboral' calculados.\")\n",
        "\n",
        "# 3.8. Más Atributos Opcionales (puedes añadir o modificar según tus necesidades)\n",
        "# dim_fecha['Dia_del_Anio'] = dim_fecha['Fecha_Completa'].dt.dayofyear # Día del año (1-366)\n",
        "# dim_fecha['Nombre_Corta_Mes'] = dim_fecha['Fecha_Completa'].dt.strftime('%b') # Ej. 'Jan'\n",
        "# dim_fecha['Inicio_Semana'] = dim_fecha['Fecha_Completa'].dt.to_period('W').start_time\n",
        "# dim_fecha['Inicio_Mes'] = dim_fecha['Fecha_Completa'].dt.to_period('M').start_time\n",
        "# dim_fecha['Inicio_Trimestre'] = dim_fecha['Fecha_Completa'].dt.to_period('Q').start_time\n",
        "# dim_fecha['Inicio_Anio'] = dim_fecha['Fecha_Completa'].dt.to_period('Y').start_time\n",
        "\n",
        "print(\"\\nVista previa de DimFecha con todos los atributos:\")\n",
        "print(dim_fecha.head())\n",
        "print(dim_fecha.tail())\n",
        "print(f\"  Número total de filas en DimFecha: {len(dim_fecha)}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "\n",
        "# --- PASO 4: Seleccionar y Reordenar Columnas (Buena Práctica) ---\n",
        "print(\"PASO 4: Seleccionando y reordenando las columnas finales de DimFecha...\")\n",
        "\n",
        "# Define el orden deseado de las columnas\n",
        "column_order = [\n",
        "    'Fecha_ID',\n",
        "    'Fecha_Completa',\n",
        "    'Anio',\n",
        "    'Mes',\n",
        "    'Nombre_Mes',\n",
        "    'Dia',\n",
        "    'Dia_de_la_Semana',\n",
        "    'Nombre_Dia_Semana',\n",
        "    'Semana_del_Anio',\n",
        "    'Trimestre',\n",
        "    'Nombre_Trimestre',\n",
        "    'Es_Fin_De_Semana',\n",
        "    'Es_Dia_Laboral'\n",
        "]\n",
        "\n",
        "# Aplica el orden al DataFrame\n",
        "dim_fecha = dim_fecha[column_order]\n",
        "\n",
        "print(\"  Columnas finales de DimFecha reordenadas.\")\n",
        "print(\"\\nDimFecha final:\")\n",
        "print(dim_fecha.head())\n",
        "print(f\"\\nInformación del DataFrame DimFecha (tipos de datos y nulos):\")\n",
        "dim_fecha.info()\n",
        "print(\"-\" * 70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g52X127fVQAs",
        "outputId": "6e861426-3b83-49ee-c1af-6cefdd40d49f"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Fecha mínima en datos: 2016-01-11 07:51:20\n",
            "  Fecha máxima en datos: 2017-12-03 16:28:00\n",
            "  Rango de DimFecha generado de: 2016-01-11 a 2017-12-04\n",
            "  Número de días en el rango: 694\n",
            "----------------------------------------------------------------------\n",
            "PASO 2: Creando el DataFrame base de DimFecha...\n",
            "  DataFrame base de DimFecha creado con la columna 'Fecha_Completa'.\n",
            "  Fecha_Completa\n",
            "0     2016-01-11\n",
            "1     2016-01-12\n",
            "2     2016-01-13\n",
            "3     2016-01-14\n",
            "4     2016-01-15\n",
            "----------------------------------------------------------------------\n",
            "PASO 3: Calculando y añadiendo los atributos temporales a DimFecha...\n",
            "  - 'Fecha_ID' calculada.\n",
            "  - 'Anio', 'Mes', 'Dia' calculados.\n",
            "  - 'Nombre_Mes', 'Nombre_Dia_Semana' calculados.\n",
            "  - 'Dia_de_la_Semana' calculada (1=Lunes, 7=Domingo).\n",
            "  - 'Semana_del_Anio' calculada.\n",
            "  - 'Trimestre', 'Nombre_Trimestre' calculados.\n",
            "  - 'Es_Fin_De_Semana', 'Es_Dia_Laboral' calculados.\n",
            "\n",
            "Vista previa de DimFecha con todos los atributos:\n",
            "  Fecha_Completa  Fecha_ID  Anio  Mes  Dia Nombre_Mes Nombre_Dia_Semana  \\\n",
            "0     2016-01-11  20160111  2016    1   11    January            Monday   \n",
            "1     2016-01-12  20160112  2016    1   12    January           Tuesday   \n",
            "2     2016-01-13  20160113  2016    1   13    January         Wednesday   \n",
            "3     2016-01-14  20160114  2016    1   14    January          Thursday   \n",
            "4     2016-01-15  20160115  2016    1   15    January            Friday   \n",
            "\n",
            "   Dia_de_la_Semana  Semana_del_Anio  Trimestre Nombre_Trimestre  \\\n",
            "0                 1                2          1          Q1-2016   \n",
            "1                 2                2          1          Q1-2016   \n",
            "2                 3                2          1          Q1-2016   \n",
            "3                 4                2          1          Q1-2016   \n",
            "4                 5                2          1          Q1-2016   \n",
            "\n",
            "   Es_Fin_De_Semana  Es_Dia_Laboral  \n",
            "0             False            True  \n",
            "1             False            True  \n",
            "2             False            True  \n",
            "3             False            True  \n",
            "4             False            True  \n",
            "    Fecha_Completa  Fecha_ID  Anio  Mes  Dia Nombre_Mes Nombre_Dia_Semana  \\\n",
            "689     2017-11-30  20171130  2017   11   30   November          Thursday   \n",
            "690     2017-12-01  20171201  2017   12    1   December            Friday   \n",
            "691     2017-12-02  20171202  2017   12    2   December          Saturday   \n",
            "692     2017-12-03  20171203  2017   12    3   December            Sunday   \n",
            "693     2017-12-04  20171204  2017   12    4   December            Monday   \n",
            "\n",
            "     Dia_de_la_Semana  Semana_del_Anio  Trimestre Nombre_Trimestre  \\\n",
            "689                 4               48          4          Q4-2017   \n",
            "690                 5               48          4          Q4-2017   \n",
            "691                 6               48          4          Q4-2017   \n",
            "692                 7               48          4          Q4-2017   \n",
            "693                 1               49          4          Q4-2017   \n",
            "\n",
            "     Es_Fin_De_Semana  Es_Dia_Laboral  \n",
            "689             False            True  \n",
            "690             False            True  \n",
            "691              True           False  \n",
            "692              True           False  \n",
            "693             False            True  \n",
            "  Número total de filas en DimFecha: 694\n",
            "----------------------------------------------------------------------\n",
            "PASO 4: Seleccionando y reordenando las columnas finales de DimFecha...\n",
            "  Columnas finales de DimFecha reordenadas.\n",
            "\n",
            "DimFecha final:\n",
            "   Fecha_ID Fecha_Completa  Anio  Mes Nombre_Mes  Dia  Dia_de_la_Semana  \\\n",
            "0  20160111     2016-01-11  2016    1    January   11                 1   \n",
            "1  20160112     2016-01-12  2016    1    January   12                 2   \n",
            "2  20160113     2016-01-13  2016    1    January   13                 3   \n",
            "3  20160114     2016-01-14  2016    1    January   14                 4   \n",
            "4  20160115     2016-01-15  2016    1    January   15                 5   \n",
            "\n",
            "  Nombre_Dia_Semana  Semana_del_Anio  Trimestre Nombre_Trimestre  \\\n",
            "0            Monday                2          1          Q1-2016   \n",
            "1           Tuesday                2          1          Q1-2016   \n",
            "2         Wednesday                2          1          Q1-2016   \n",
            "3          Thursday                2          1          Q1-2016   \n",
            "4            Friday                2          1          Q1-2016   \n",
            "\n",
            "   Es_Fin_De_Semana  Es_Dia_Laboral  \n",
            "0             False            True  \n",
            "1             False            True  \n",
            "2             False            True  \n",
            "3             False            True  \n",
            "4             False            True  \n",
            "\n",
            "Información del DataFrame DimFecha (tipos de datos y nulos):\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 694 entries, 0 to 693\n",
            "Data columns (total 13 columns):\n",
            " #   Column             Non-Null Count  Dtype         \n",
            "---  ------             --------------  -----         \n",
            " 0   Fecha_ID           694 non-null    int64         \n",
            " 1   Fecha_Completa     694 non-null    datetime64[ns]\n",
            " 2   Anio               694 non-null    int32         \n",
            " 3   Mes                694 non-null    int32         \n",
            " 4   Nombre_Mes         694 non-null    object        \n",
            " 5   Dia                694 non-null    int32         \n",
            " 6   Dia_de_la_Semana   694 non-null    int32         \n",
            " 7   Nombre_Dia_Semana  694 non-null    object        \n",
            " 8   Semana_del_Anio    694 non-null    int64         \n",
            " 9   Trimestre          694 non-null    int32         \n",
            " 10  Nombre_Trimestre   694 non-null    object        \n",
            " 11  Es_Fin_De_Semana   694 non-null    bool          \n",
            " 12  Es_Dia_Laboral     694 non-null    bool          \n",
            "dtypes: bool(2), datetime64[ns](1), int32(5), int64(2), object(3)\n",
            "memory usage: 47.6+ KB\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define el nombre de tu archivo Parquet\n",
        "nombre_archivo1 = 'dimension_fecha_plata.parquet'\n",
        "full_path = os.path.join('/content/plata', nombre_archivo1)\n",
        "print(full_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLuucRhVM8Tk",
        "outputId": "d8d27cae-691b-46ff-9ef9-6d55ee53ee53"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/plata/dimension_fecha_plata.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guarda el DataFrame en formato Parquet\n",
        "# index=False es importante para no guardar el índice del DataFrame como una columna\n",
        "dim_fecha.to_parquet(full_path, index=False)\n",
        "\n",
        "print(f\"\\nDataFrame guardado exitosamente en la capa Plata como: {full_path}\")\n",
        "print(\"Puedes verificarlo en tu Google Drive en esa ruta.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upH6xLxBPjoC",
        "outputId": "f7332da0-ef8b-48f4-f203-fde58c53fc4b"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame guardado exitosamente en la capa Plata como: /content/plata/dimension_fecha_plata.parquet\n",
            "Puedes verificarlo en tu Google Drive en esa ruta.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_leido1 = pd.read_parquet('/content/plata/dimension_fecha_plata.parquet')\n",
        "\n",
        "print(f\"\\nDataFrame leído de 'bakery_sales_bronze.parquet':\")\n",
        "print(df_leido1.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9zALE0HW1d_",
        "outputId": "f838e021-40e5-4818-f90f-1725a4d44de2"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame leído de 'bakery_sales_bronze.parquet':\n",
            "   Fecha_ID Fecha_Completa  Anio  Mes Nombre_Mes  Dia  Dia_de_la_Semana  \\\n",
            "0  20160111     2016-01-11  2016    1    January   11                 1   \n",
            "1  20160112     2016-01-12  2016    1    January   12                 2   \n",
            "2  20160113     2016-01-13  2016    1    January   13                 3   \n",
            "3  20160114     2016-01-14  2016    1    January   14                 4   \n",
            "4  20160115     2016-01-15  2016    1    January   15                 5   \n",
            "\n",
            "  Nombre_Dia_Semana  Semana_del_Anio  Trimestre Nombre_Trimestre  \\\n",
            "0            Monday                2          1          Q1-2016   \n",
            "1           Tuesday                2          1          Q1-2016   \n",
            "2         Wednesday                2          1          Q1-2016   \n",
            "3          Thursday                2          1          Q1-2016   \n",
            "4            Friday                2          1          Q1-2016   \n",
            "\n",
            "   Es_Fin_De_Semana  Es_Dia_Laboral  \n",
            "0             False            True  \n",
            "1             False            True  \n",
            "2             False            True  \n",
            "3             False            True  \n",
            "4             False            True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dimension Producto"
      ],
      "metadata": {
        "id": "iym0bA17XYSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_leido = pd.read_parquet('/content/bronze/bakery_sales_bronze.parquet')\n",
        "\n",
        "print(f\"\\nDataFrame leído de 'bakery_sales_bronze.parquet':\")\n",
        "\n",
        "\n",
        "print(df_leido.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBCRGQlOXQk9",
        "outputId": "4eec1049-8b1f-4ac7-ff6a-8c1c9c4059f2"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame leído de 'bakery_sales_bronze.parquet':\n",
            "   TransactionNo          Items             DateTime  Daypart  DayType  \\\n",
            "0              1          Bread  2016-10-30 09:58:11  Morning  Weekend   \n",
            "1              2   Scandinavian  2016-10-30 10:05:34  Morning  Weekend   \n",
            "2              2   Scandinavian  2016-10-30 10:05:34  Morning  Weekend   \n",
            "3              3  Hot chocolate  2016-10-30 10:07:57  Morning  Weekend   \n",
            "4              3            Jam  2016-10-30 10:07:57  Morning  Weekend   \n",
            "\n",
            "   ID_Tienda_Aleatoria  store_id           store_name    city  \\\n",
            "0                  160       160    Tienda 160 - Jaén    Jaén   \n",
            "1                  153       153    Tienda 153 - Jaén    Jaén   \n",
            "2                  381       381  Tienda 381 - Murcia  Murcia   \n",
            "3                    2         2    Tienda 2 - Burgos  Burgos   \n",
            "4                  536       536    Tienda 536 - León    León   \n",
            "\n",
            "            region opening_date  Cantidad  Precio_Unitario  Total_Producto  \n",
            "0          Levante   2020-05-18         1            17.77           17.77  \n",
            "1           Aragón   2019-09-24         3            11.20           33.60  \n",
            "2  Castilla y León   2023-12-18         4             6.10           24.40  \n",
            "3           Centro   2024-05-02         5             7.84           39.20  \n",
            "4          Levante   2017-02-13         5             1.09            5.45  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Obteniendo la Dimensión Producto...\")\n",
        "df_dim_products = generate_products_data_custom(NUM_PRODUCTOS_OBJETIVO, fake)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTa15M8ug5Bx",
        "outputId": "05e2e56e-9bc5-43a5-f13f-bcdb902320a1"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obteniendo la Dimensión Producto...\n",
            "Generando datos para DimProducto (200 productos, incluyendo clasificación de pan)...\n",
            "Datos de productos generados: 200 registros.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- DataFrame de la Dimensión Producto (Columnas solicitadas) ---\")\n",
        "\n",
        "# Seleccionar las columnas usando sus nombres CORRECTOS de df_dim_products\n",
        "# product_name en lugar de 'nombre'\n",
        "# category en lugar de 'categoria'\n",
        "# price en lugar de 'precio'\n",
        "df_display = df_dim_products[['product_id', 'product_name', 'category', 'price']].copy()\n",
        "\n",
        "# Ahora sí, renombrar las columnas según la solicitud del usuario\n",
        "df_display.rename(columns={\n",
        "    'product_id': 'ID_Producto',\n",
        "    'product_name': 'Nombre_Producto',\n",
        "    'category': 'Clasificacion_Producto',\n",
        "    'price': 'Precio_Base'\n",
        "}, inplace=True)\n",
        "\n",
        "print(df_display.head())\n",
        "print(f\"\\nNúmero total de productos en la dimensión: {len(df_display)}\")\n",
        "print(\"\\nColumnas y tipos de datos:\")\n",
        "df_display.info()\n",
        "print(\"-\" * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SkkB-HgPlV0o",
        "outputId": "dda53f98-b441-429b-88e9-851e89a951f0"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- DataFrame de la Dimensión Producto (Columnas solicitadas) ---\n",
            "   ID_Producto   Nombre_Producto Clasificacion_Producto  Precio_Base\n",
            "0            1     Music Gen 135            Bebida Fría        12.13\n",
            "1            2       Flan casero             Repostería        37.93\n",
            "2            3     Image Gen 176       Bocadillo Salado        26.91\n",
            "3            4          Buñuelos        Bebida Caliente        24.47\n",
            "4            5  Cereal con leche       Bocadillo Salado        40.16\n",
            "\n",
            "Número total de productos en la dimensión: 200\n",
            "\n",
            "Columnas y tipos de datos:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 200 entries, 0 to 199\n",
            "Data columns (total 4 columns):\n",
            " #   Column                  Non-Null Count  Dtype  \n",
            "---  ------                  --------------  -----  \n",
            " 0   ID_Producto             200 non-null    int64  \n",
            " 1   Nombre_Producto         200 non-null    object \n",
            " 2   Clasificacion_Producto  200 non-null    object \n",
            " 3   Precio_Base             200 non-null    float64\n",
            "dtypes: float64(1), int64(1), object(2)\n",
            "memory usage: 6.4+ KB\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define el nombre de tu archivo Parquet\n",
        "nombre_archivo2 = 'dimension_producto_plata.parquet'\n",
        "full_path = os.path.join('/content/plata', nombre_archivo2)\n",
        "print(full_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjfdTckigxQI",
        "outputId": "00cb3583-a72e-4eab-f69b-eb39a7d7a953"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/plata/dimension_producto_plata.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guarda el DataFrame en formato Parquet\n",
        "# index=False es importante para no guardar el índice del DataFrame como una columna\n",
        "df_display.to_parquet(full_path, index=False)\n",
        "\n",
        "print(f\"\\nDataFrame guardado exitosamente en la capa Plata como: {full_path}\")\n",
        "print(\"Puedes verificarlo en tu Google Drive en esa ruta.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwRFQIVbmIW-",
        "outputId": "8085cdc5-eacb-4e56-e073-411c6baa4665"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame guardado exitosamente en la capa Plata como: /content/plata/dimension_producto_plata.parquet\n",
            "Puedes verificarlo en tu Google Drive en esa ruta.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_leido2 = pd.read_parquet('/content/plata/dimension_producto_plata.parquet')\n",
        "\n",
        "print(f\"\\nDataFrame leído :\")\n",
        "print(df_leido2.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "k11Edslxmjf7",
        "outputId": "a785318d-aa38-4904-f693-25c9b27b1de7"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame leído :\n",
            "   ID_Producto   Nombre_Producto Clasificacion_Producto  Precio_Base\n",
            "0            1     Music Gen 135            Bebida Fría        12.13\n",
            "1            2       Flan casero             Repostería        37.93\n",
            "2            3     Image Gen 176       Bocadillo Salado        26.91\n",
            "3            4          Buñuelos        Bebida Caliente        24.47\n",
            "4            5  Cereal con leche       Bocadillo Salado        40.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DIMENSIONN TIENDA"
      ],
      "metadata": {
        "id": "UBmGt6O9oAde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_leido = pd.read_parquet('/content/bronze/bakery_sales_bronze.parquet')\n",
        "\n",
        "print(f\"\\nDataFrame leído de 'bakery_sales_bronze.parquet':\")\n",
        "\n",
        "\n",
        "print(df_leido.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOjsmVI-oF4S",
        "outputId": "3eec4934-6bde-4097-d056-b1e01ef1fc14"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame leído de 'bakery_sales_bronze.parquet':\n",
            "   TransactionNo          Items             DateTime  Daypart  DayType  \\\n",
            "0              1          Bread  2016-10-30 09:58:11  Morning  Weekend   \n",
            "1              2   Scandinavian  2016-10-30 10:05:34  Morning  Weekend   \n",
            "2              2   Scandinavian  2016-10-30 10:05:34  Morning  Weekend   \n",
            "3              3  Hot chocolate  2016-10-30 10:07:57  Morning  Weekend   \n",
            "4              3            Jam  2016-10-30 10:07:57  Morning  Weekend   \n",
            "\n",
            "   ID_Tienda_Aleatoria  store_id           store_name    city  \\\n",
            "0                  160       160    Tienda 160 - Jaén    Jaén   \n",
            "1                  153       153    Tienda 153 - Jaén    Jaén   \n",
            "2                  381       381  Tienda 381 - Murcia  Murcia   \n",
            "3                    2         2    Tienda 2 - Burgos  Burgos   \n",
            "4                  536       536    Tienda 536 - León    León   \n",
            "\n",
            "            region opening_date  Cantidad  Precio_Unitario  Total_Producto  \n",
            "0          Levante   2020-05-18         1            17.77           17.77  \n",
            "1           Aragón   2019-09-24         3            11.20           33.60  \n",
            "2  Castilla y León   2023-12-18         4             6.10           24.40  \n",
            "3           Centro   2024-05-02         5             7.84           39.20  \n",
            "4          Levante   2017-02-13         5             1.09            5.45  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dim_tienda_base = df_final[['store_id', 'store_name', 'city', 'region', 'opening_date']].drop_duplicates(subset=['store_id']).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "Ksl3HVa7px_6"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Renombrar columnas para que coincidan con la convención de DimTienda\n",
        "dim_tienda_base = dim_tienda_base.rename(columns={\n",
        "    'store_id': 'Tienda_ID',\n",
        "    'store_name': 'Nombre_Tienda',\n",
        "    'city': 'Ciudad',\n",
        "    'region': 'Region_Geografica', # Renombramos para distinguirla del 'Estado' si es necesario\n",
        "    'opening_date': 'Fecha_Apertura'\n",
        "})\n",
        "\n",
        "print(\"  Datos únicos de tiendas extraídos:\")\n",
        "print(dim_tienda_base.head())\n",
        "print(f\"  Número de tiendas únicas encontradas: {len(dim_tienda_base)}\")\n",
        "print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkeLjf1rqC_y",
        "outputId": "2800a247-8edd-4921-84f9-6cc6b8932586"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Datos únicos de tiendas extraídos:\n",
            "   Tienda_ID        Nombre_Tienda  Ciudad Region_Geografica Fecha_Apertura\n",
            "0        160    Tienda 160 - Jaén    Jaén           Levante     2020-05-18\n",
            "1        153    Tienda 153 - Jaén    Jaén            Aragón     2019-09-24\n",
            "2        381  Tienda 381 - Murcia  Murcia   Castilla y León     2023-12-18\n",
            "3          2    Tienda 2 - Burgos  Burgos            Centro     2024-05-02\n",
            "4        536    Tienda 536 - León    León           Levante     2017-02-13\n",
            "  Número de tiendas únicas encontradas: 1000\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Mapeo simple de regiones a estados (ejemplo, ajusta según tu lógica)\n",
        "# Si 'region' ya representa el estado, puedes simplemente asignar:\n",
        "# dim_tienda_base['Estado'] = dim_tienda_base['Region_Geografica']\n",
        "\n",
        "# Si 'region' es más amplia (ej. 'Norte') y necesitas un 'Estado' más específico:\n",
        "# Puedes crear un mapeo más complejo o generar aleatoriamente.\n",
        "# Para este ejemplo, supondremos un mapeo simple basado en las regiones mostradas en tus datos\n",
        "region_to_estado_map = {\n",
        "    'Levante': 'Comunidad Valenciana',\n",
        "    'Aragón': 'Aragón',\n",
        "    'Castilla y Leon': 'Castilla y León',\n",
        "    'Centro': 'Comunidad de Madrid', # O Castilla-La Mancha, etc.\n",
        "    'Noroeste': 'Galicia', # O Asturias, Cantabria\n",
        "    'Norte': 'País Vasco', # O Cantabria, Asturias\n",
        "    'Andalucía': 'Andalucía'\n",
        "}\n",
        "dim_tienda_base['Estado'] = dim_tienda_base['Region_Geografica'].map(region_to_estado_map).fillna('Desconocido')\n",
        "\n",
        "print(\"  Columna 'Estado' añadida.\")\n",
        "print(dim_tienda_base.head())\n",
        "print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOg8q8uFqVg5",
        "outputId": "e0bcbac4-5124-402a-cb99-54434f648872"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Columna 'Estado' añadida.\n",
            "   Tienda_ID        Nombre_Tienda  Ciudad Region_Geografica Fecha_Apertura  \\\n",
            "0        160    Tienda 160 - Jaén    Jaén           Levante     2020-05-18   \n",
            "1        153    Tienda 153 - Jaén    Jaén            Aragón     2019-09-24   \n",
            "2        381  Tienda 381 - Murcia  Murcia   Castilla y León     2023-12-18   \n",
            "3          2    Tienda 2 - Burgos  Burgos            Centro     2024-05-02   \n",
            "4        536    Tienda 536 - León    León           Levante     2017-02-13   \n",
            "\n",
            "                 Estado  \n",
            "0  Comunidad Valenciana  \n",
            "1                Aragón  \n",
            "2           Desconocido  \n",
            "3   Comunidad de Madrid  \n",
            "4  Comunidad Valenciana  \n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PASO 3: Añadir la Columna 'Tipo_Tienda' (Generado Aleatoriamente) ---\n",
        "\n",
        "\n",
        "tipos_tienda_posibles = [\n",
        "    'Panadería Artesanal', 'Cafetería Especializada', 'Panadería Express',\n",
        "    'Boutique de Pan', 'Tienda de Conveniencia', 'Gourmet'\n",
        "]\n",
        "\n",
        "dim_tienda_base['Tipo_Tienda'] = [random.choice(tipos_tienda_posibles) for _ in range(len(dim_tienda_base))]\n",
        "\n",
        "print(\"  Columna 'Tipo_Tienda' añadida.\")\n",
        "print(dim_tienda_base.head())\n",
        "print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJorKu9eqXL7",
        "outputId": "7a3549c3-b890-474b-c16c-5cd6450f9e13"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Columna 'Tipo_Tienda' añadida.\n",
            "   Tienda_ID        Nombre_Tienda  Ciudad Region_Geografica Fecha_Apertura  \\\n",
            "0        160    Tienda 160 - Jaén    Jaén           Levante     2020-05-18   \n",
            "1        153    Tienda 153 - Jaén    Jaén            Aragón     2019-09-24   \n",
            "2        381  Tienda 381 - Murcia  Murcia   Castilla y León     2023-12-18   \n",
            "3          2    Tienda 2 - Burgos  Burgos            Centro     2024-05-02   \n",
            "4        536    Tienda 536 - León    León           Levante     2017-02-13   \n",
            "\n",
            "                 Estado              Tipo_Tienda  \n",
            "0  Comunidad Valenciana  Cafetería Especializada  \n",
            "1                Aragón      Panadería Artesanal  \n",
            "2           Desconocido          Boutique de Pan  \n",
            "3   Comunidad de Madrid  Cafetería Especializada  \n",
            "4  Comunidad Valenciana   Tienda de Conveniencia  \n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "column_order_dim_tienda = [\n",
        "    'Tienda_ID',\n",
        "    'Nombre_Tienda',\n",
        "    'Ciudad',\n",
        "    'Estado',        # Nueva columna\n",
        "    'Region_Geografica', # La columna 'region' original, renombrada\n",
        "    'Tipo_Tienda',   # Nueva columna\n",
        "    'Fecha_Apertura' # La columna 'opening_date' original\n",
        "]\n",
        "\n",
        "dim_tienda = dim_tienda_base[column_order_dim_tienda]\n",
        "print(\"\\nDimTienda final:\")\n",
        "print(dim_tienda.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SsBSkXtVqh2s",
        "outputId": "dc6d0d59-a8ae-4d8b-f00c-d85c53bbee92"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DimTienda final:\n",
            "   Tienda_ID        Nombre_Tienda  Ciudad                Estado  \\\n",
            "0        160    Tienda 160 - Jaén    Jaén  Comunidad Valenciana   \n",
            "1        153    Tienda 153 - Jaén    Jaén                Aragón   \n",
            "2        381  Tienda 381 - Murcia  Murcia           Desconocido   \n",
            "3          2    Tienda 2 - Burgos  Burgos   Comunidad de Madrid   \n",
            "4        536    Tienda 536 - León    León  Comunidad Valenciana   \n",
            "\n",
            "  Region_Geografica              Tipo_Tienda Fecha_Apertura  \n",
            "0           Levante  Cafetería Especializada     2020-05-18  \n",
            "1            Aragón      Panadería Artesanal     2019-09-24  \n",
            "2   Castilla y León          Boutique de Pan     2023-12-18  \n",
            "3            Centro  Cafetería Especializada     2024-05-02  \n",
            "4           Levante   Tienda de Conveniencia     2017-02-13  \n",
            "\n",
            "Número total de tiendas en DimTienda: 1000\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 7 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   Tienda_ID          1000 non-null   int64 \n",
            " 1   Nombre_Tienda      1000 non-null   object\n",
            " 2   Ciudad             1000 non-null   object\n",
            " 3   Estado             1000 non-null   object\n",
            " 4   Region_Geografica  1000 non-null   object\n",
            " 5   Tipo_Tienda        1000 non-null   object\n",
            " 6   Fecha_Apertura     1000 non-null   object\n",
            "dtypes: int64(1), object(6)\n",
            "memory usage: 54.8+ KB\n",
            "Información de DimTienda: None\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\nNúmero total de tiendas en DimTienda: {len(dim_tienda)}\")\n",
        "print(f\"Información de DimTienda: {dim_tienda.info()}\")\n",
        "print(\"-\" * 80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nzgdqbXTqu8Q",
        "outputId": "4bbae62e-c618-4ffa-f1fb-6d435d2a98e8"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Número total de tiendas en DimTienda: 1000\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 7 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   Tienda_ID          1000 non-null   int64 \n",
            " 1   Nombre_Tienda      1000 non-null   object\n",
            " 2   Ciudad             1000 non-null   object\n",
            " 3   Estado             1000 non-null   object\n",
            " 4   Region_Geografica  1000 non-null   object\n",
            " 5   Tipo_Tienda        1000 non-null   object\n",
            " 6   Fecha_Apertura     1000 non-null   object\n",
            "dtypes: int64(1), object(6)\n",
            "memory usage: 54.8+ KB\n",
            "Información de DimTienda: None\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define el nombre de tu archivo Parquet\n",
        "nombre_archivo3 = 'dimension_tienda_plata.parquet'\n",
        "full_path = os.path.join('/content/plata', nombre_archivo3)\n",
        "print(full_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogRhQnHOq1BQ",
        "outputId": "21539cb0-54c1-402c-fb1c-9af6a747bb58"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/plata/dimension_tienda_plata.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guarda el DataFrame en formato Parquet\n",
        "# index=False es importante para no guardar el índice del DataFrame como una columna\n",
        "dim_tienda.to_parquet(full_path, index=False)\n",
        "\n",
        "print(f\"\\nDataFrame guardado exitosamente en la capa Plata como: {full_path}\")\n",
        "print(\"Puedes verificarlo en tu Google Drive en esa ruta.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2MXOqr4rVWB",
        "outputId": "4d7325b2-8bf9-4501-a617-fe971e8864d2"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame guardado exitosamente en la capa Plata como: /content/plata/dimension_tienda_plata.parquet\n",
            "Puedes verificarlo en tu Google Drive en esa ruta.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_leido3 = pd.read_parquet('/content/plata/dimension_tienda_plata.parquet')\n",
        "\n",
        "print(f\"\\nDataFrame leído :\")\n",
        "print(df_leido3.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6qMrnypru6i",
        "outputId": "1e021d18-e8a8-463b-f560-2e8b75641457"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame leído :\n",
            "   Tienda_ID        Nombre_Tienda  Ciudad                Estado  \\\n",
            "0        160    Tienda 160 - Jaén    Jaén  Comunidad Valenciana   \n",
            "1        153    Tienda 153 - Jaén    Jaén                Aragón   \n",
            "2        381  Tienda 381 - Murcia  Murcia           Desconocido   \n",
            "3          2    Tienda 2 - Burgos  Burgos   Comunidad de Madrid   \n",
            "4        536    Tienda 536 - León    León  Comunidad Valenciana   \n",
            "\n",
            "  Region_Geografica              Tipo_Tienda Fecha_Apertura  \n",
            "0           Levante  Cafetería Especializada     2020-05-18  \n",
            "1            Aragón      Panadería Artesanal     2019-09-24  \n",
            "2   Castilla y León          Boutique de Pan     2023-12-18  \n",
            "3            Centro  Cafetería Especializada     2024-05-02  \n",
            "4           Levante   Tienda de Conveniencia     2017-02-13  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tabla de hechos Ventas"
      ],
      "metadata": {
        "id": "9-w0SpTysvkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_leido = pd.read_parquet('/content/bronze/bakery_sales_bronze.parquet')\n",
        "\n",
        "print(f\"\\nDataFrame leído de 'bakery_sales_bronze.parquet':\")\n",
        "\n",
        "\n",
        "print(df_leido.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSbUIo8CsACS",
        "outputId": "9922bef0-d453-4629-b70f-1ff4130072ed"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame leído de 'bakery_sales_bronze.parquet':\n",
            "   TransactionNo          Items             DateTime  Daypart  DayType  \\\n",
            "0              1          Bread  2016-10-30 09:58:11  Morning  Weekend   \n",
            "1              2   Scandinavian  2016-10-30 10:05:34  Morning  Weekend   \n",
            "2              2   Scandinavian  2016-10-30 10:05:34  Morning  Weekend   \n",
            "3              3  Hot chocolate  2016-10-30 10:07:57  Morning  Weekend   \n",
            "4              3            Jam  2016-10-30 10:07:57  Morning  Weekend   \n",
            "\n",
            "   ID_Tienda_Aleatoria  store_id           store_name    city  \\\n",
            "0                  160       160    Tienda 160 - Jaén    Jaén   \n",
            "1                  153       153    Tienda 153 - Jaén    Jaén   \n",
            "2                  381       381  Tienda 381 - Murcia  Murcia   \n",
            "3                    2         2    Tienda 2 - Burgos  Burgos   \n",
            "4                  536       536    Tienda 536 - León    León   \n",
            "\n",
            "            region opening_date  Cantidad  Precio_Unitario  Total_Producto  \n",
            "0          Levante   2020-05-18         1            17.77           17.77  \n",
            "1           Aragón   2019-09-24         3            11.20           33.60  \n",
            "2  Castilla y León   2023-12-18         4             6.10           24.40  \n",
            "3           Centro   2024-05-02         5             7.84           39.20  \n",
            "4          Levante   2017-02-13         5             1.09            5.45  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionar las columnas directamente relevantes para la tabla de hechos\n",
        "# Usaremos 'store_id' ya que parece ser la columna de ID de tienda en tu df_final\n",
        "fact_ventas = df_final[[\n",
        "    'TransactionNo', 'DateTime', 'Items', 'store_id', # <-- CAMBIO AQUÍ: Usamos 'store_id'\n",
        "    'Cantidad', 'Precio_Unitario', 'Total_Producto', 'Daypart', 'DayType'\n",
        "]].copy()\n",
        "\n",
        "print(\"  DataFrame base de FactVentas creado:\")\n",
        "print(fact_ventas.head())\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# --- Continúa con la lógica de renombrar 'store_id' a 'Tienda_ID' más adelante ---\n",
        "# Puedes renombrarlo aquí si lo prefieres, o en el paso 5 como estaba antes.\n",
        "# Por ejemplo, justo después de crear fact_ventas:\n",
        "fact_ventas = fact_ventas.rename(columns={'store_id': 'Tienda_ID'})\n",
        "print(\"  'store_id' renombrado a 'Tienda_ID'.\")\n",
        "print(fact_ventas.head())\n",
        "print(\"-\" * 80)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "CNVhwTQotYe6",
        "outputId": "010cf5d0-c4c9-4212-f61f-cebafb2065b7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_final' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-89bf36f875fb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Seleccionar las columnas directamente relevantes para la tabla de hechos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Usaremos 'store_id' ya que parece ser la columna de ID de tienda en tu df_final\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m fact_ventas = df_final[[\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;34m'TransactionNo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'DateTime'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Items'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'store_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# <-- CAMBIO AQUÍ: Usamos 'store_id'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'Cantidad'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Precio_Unitario'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Total_Producto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Daypart'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'DayType'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_final' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_leido2 = pd.read_parquet('/content/plata/dimension_producto_plata.parquet')"
      ],
      "metadata": {
        "id": "y96bQdviuwNJ"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dim_producto = df_leido2"
      ],
      "metadata": {
        "id": "gjmCtNyW3nap"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    df_temp_producto = pd.read_parquet(dim_producto)\n",
        "    # Aquí, como has demostrado que df_temp_producto ya tiene las columnas correctas,\n",
        "    # la lógica 'elif 'Producto_ID' in df_temp_producto.columns...' se ejecutará\n",
        "    # y asignará df_temp_producto directamente a dim_producto.\n",
        "    if 'product_id' in df_temp_producto.columns and 'product_name' in df_temp_producto.columns:\n",
        "        dim_producto = df_temp_producto.rename(columns={\n",
        "            'product_id': 'Producto_ID',\n",
        "            'product_name': 'Nombre_Producto',\n",
        "            'category': 'Clasificacion_Producto',\n",
        "            'price': 'Precio_Base'\n",
        "        })\n",
        "    elif 'Producto_ID' in df_temp_producto.columns and 'Nombre_Producto' in df_temp_producto.columns: # Esta condición debería ser verdadera ahora\n",
        "        dim_producto = df_temp_producto\n",
        "    else:\n",
        "        # Esto solo se ejecutaría si hay un problema inesperado con las columnas\n",
        "        print(\"ADVERTENCIA: Columnas esperadas no encontradas. Creando dim_producto de demostración.\")\n",
        "        dim_producto = pd.DataFrame({\n",
        "            'Producto_ID': [1, 2],\n",
        "            'Nombre_Producto': ['Pan', 'Café'],\n",
        "            'Precio_Base_Producto': [2.5, 3.0]\n",
        "        })\n",
        "    print(f\"DimProducto cargada exitosamente. Filas: {len(dim_producto)}. Columnas: {dim_producto.columns.tolist()}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: Archivo no encontrado en {dim_producto_path}. Creando dim_producto de demostración.\")\n",
        "    dim_producto = pd.DataFrame({\n",
        "        'Producto_ID': [1, 2],\n",
        "        'Nombre_Producto': ['Pan', 'Café'],\n",
        "        'Precio_Base_Producto': [2.5, 3.0]\n",
        "    })\n",
        "except Exception as e:\n",
        "    print(f\"ERROR inesperado al cargar DimProducto: {e}. Creando dim_producto de demostración.\")\n",
        "    dim_producto = pd.DataFrame({\n",
        "        'Producto_ID': [1, 2],\n",
        "        'Nombre_Producto': ['Pan', 'Café'],\n",
        "        'Precio_Base_Producto': [2.5, 3.0]\n",
        "    })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ORHLqMbu5ahb",
        "outputId": "70fcaaed-52e4-46f6-e7e1-360a5842403c"
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR inesperado al cargar DimProducto: cannot construct a FileSource from      ID_Producto            Nombre_Producto Clasificacion_Producto  \\\n",
            "0              1              Music Gen 135            Bebida Fría   \n",
            "1              2                Flan casero             Repostería   \n",
            "2              3              Image Gen 176       Bocadillo Salado   \n",
            "3              4                   Buñuelos        Bebida Caliente   \n",
            "4              5           Cereal con leche       Bocadillo Salado   \n",
            "5              6          Empanada de carne       Panes Especiales   \n",
            "6              7           Pan de Zanahoria       Panes Especiales   \n",
            "7              8             Simple Gen 197                 Salado   \n",
            "8              9                   Té Verde        Bebida Caliente   \n",
            "9             10        Tostada de aguacate                 Salado   \n",
            "10            11           American Gen 133            Bebida Fría   \n",
            "11            12              Crime Gen 143                 Salado   \n",
            "12            13                 We Gen 137             Repostería   \n",
            "13            14          Omelette de queso            Bebida Fría   \n",
            "14            15              Clear Gen 158        Bebida Caliente   \n",
            "15            16               Pull Gen 115             Repostería   \n",
            "16            17            Trouble Gen 142       Bocadillo Salado   \n",
            "17            18             Instead Gen 86            Bebida Fría   \n",
            "18            19          Cerveza artesanal            Bebida Fría   \n",
            "19            20           Crepa de Nutella       Bocadillo Salado   \n",
            "20            21        Pan Germinado Vital              Pan Dulce   \n",
            "21            22            Meeting Gen 183                 Salado   \n",
            "22            23             Smoothie verde             Repostería   \n",
            "23            24        Pan Integral Casero                 Bollos   \n",
            "24            25         Pan de Ajo Rústico       Panes Especiales   \n",
            "25            26            Several Gen 164        Bebida Caliente   \n",
            "26            27            Pan Multicereal                 Bollos   \n",
            "27            28             Rather Gen 102       Bocadillo Salado   \n",
            "28            29               None Gen 101             Repostería   \n",
            "29            30             During Gen 138        Bebida Caliente   \n",
            "30            31       Brownie de Chocolate        Bebida Caliente   \n",
            "31            32               Agua con gas            Bebida Fría   \n",
            "32            33                   Baguette              Pan Dulce   \n",
            "33            34               Site Gen 134                 Salado   \n",
            "34            35                Food Gen 92       Bocadillo Salado   \n",
            "35            36           Tarta de Manzana            Bebida Fría   \n",
            "36            37          Enchiladas suizas       Bocadillo Salado   \n",
            "37            38                     Panini              Pan Dulce   \n",
            "38            39             Likely Gen 185        Bebida Caliente   \n",
            "39            40             Police Gen 162        Bebida Caliente   \n",
            "40            41          Determine Gen 174        Bebida Caliente   \n",
            "41            42         Ensalada de frutas                 Postre   \n",
            "42            43               Rise Gen 116                 Postre   \n",
            "43            44             Provide Gen 96                 Postre   \n",
            "44            45               Huge Gen 141       Bocadillo Salado   \n",
            "45            46         Barrita energética                 Postre   \n",
            "46            47          Taco de cochinita                 Postre   \n",
            "47            48              Report Gen 89        Bebida Caliente   \n",
            "48            49          Character Gen 153       Bocadillo Salado   \n",
            "49            50             Future Gen 148        Bebida Caliente   \n",
            "50            51                 Or Gen 117             Repostería   \n",
            "51            52             Speech Gen 129            Bebida Fría   \n",
            "52            53            Purpose Gen 127       Bocadillo Salado   \n",
            "53            54                Thus Gen 99                 Salado   \n",
            "54            55          Sometimes Gen 145                 Postre   \n",
            "55            56                Pan de Maíz           Pan de Molde   \n",
            "56            57         Chocolate caliente        Bebida Caliente   \n",
            "57            58            Bollos de Leche           Pan de Molde   \n",
            "58            59           Nachos con queso                 Salado   \n",
            "59            60             Huevo revuelto       Bocadillo Salado   \n",
            "60            61            Serious Gen 149       Bocadillo Salado   \n",
            "61            62               Great Gen 94                 Salado   \n",
            "62            63                Pan de Coco           Pan Integral   \n",
            "63            64        Panqueques con miel           Pan Integral   \n",
            "64            65            Latte Macchiato                 Salado   \n",
            "65            66                 Vino tinto            Bebida Fría   \n",
            "66            67            Various Gen 154        Bebida Caliente   \n",
            "67            68            Cereal integral                 Bollos   \n",
            "68            69              Muffin de Pan    Panadería Artesanal   \n",
            "69            70            Without Gen 147                 Salado   \n",
            "70            71               Color Gen 98                 Salado   \n",
            "71            72             Ensalada César        Bebida Caliente   \n",
            "72            73             Affect Gen 165                 Postre   \n",
            "73            74                Add Gen 193                 Salado   \n",
            "74            75           Sopa de verduras        Bebida Caliente   \n",
            "75            76        Pastel de chocolate                 Postre   \n",
            "76            77               Pan de Campo       Panes Especiales   \n",
            "77            78           Somebody Gen 108            Bebida Fría   \n",
            "78            79                Song Gen 93                 Salado   \n",
            "79            80             Wonder Gen 118            Bebida Fría   \n",
            "80            81          Bocadillo de Atún       Bocadillo Salado   \n",
            "81            82                   Ciabatta       Panes Especiales   \n",
            "82            83             Pizza personal                 Postre   \n",
            "83            84           Refresco de cola            Bebida Fría   \n",
            "84            85            Pan de Calabaza           Pan de Molde   \n",
            "85            86              Serve Gen 130                 Postre   \n",
            "86            87          Waffles con crema        Bebida Caliente   \n",
            "87            88            Paleta de hielo             Repostería   \n",
            "88            89               Space Gen 88            Bebida Fría   \n",
            "89            90               Agua Mineral       Bocadillo Salado   \n",
            "90            91               Hear Gen 181                 Postre   \n",
            "91            92                 So Gen 104                 Postre   \n",
            "92            93          Different Gen 120       Bocadillo Salado   \n",
            "93            94             Manage Gen 177             Repostería   \n",
            "94            95      Churros con chocolate             Repostería   \n",
            "95            96        Muffin de Arándanos           Pan de Molde   \n",
            "96            97          Available Gen 186        Bebida Caliente   \n",
            "97            98               Safe Gen 156            Bebida Fría   \n",
            "98            99                 Leg Gen 85        Bebida Caliente   \n",
            "99           100                Win Gen 160        Bebida Caliente   \n",
            "100          101           Magazine Gen 166                 Salado   \n",
            "101          102               Yogur griego                 Postre   \n",
            "102          103               Work Gen 179                 Postre   \n",
            "103          104            Project Gen 171                 Postre   \n",
            "104          105           Burrito de pollo            Bebida Fría   \n",
            "105          106              Month Gen 111            Bebida Fría   \n",
            "106          107                 Mr Gen 189            Bebida Fría   \n",
            "107          108            Produce Gen 198            Bebida Fría   \n",
            "108          109            Exactly Gen 122             Repostería   \n",
            "109          110           Galleta de Avena           Pan Integral   \n",
            "110          111             Pan de Cebolla                 Bollos   \n",
            "111          112          Gelatina de fresa                 Postre   \n",
            "112          113       Pan Dulce de Naranja           Pan de Molde   \n",
            "113          114                Trip Gen 91        Bebida Caliente   \n",
            "114          115             Pan de Espelta              Pan Dulce   \n",
            "115          116         Everything Gen 190                 Postre   \n",
            "116          117                Lot Gen 194            Bebida Fría   \n",
            "117          118              Under Gen 139       Bocadillo Salado   \n",
            "118          119               Type Gen 140            Bebida Fría   \n",
            "119          120                  Magdalena       Bocadillo Salado   \n",
            "120          121             Amount Gen 196             Repostería   \n",
            "121          122            Jugo de Naranja             Repostería   \n",
            "122          123           Yourself Gen 152             Repostería   \n",
            "123          124                 At Gen 170             Repostería   \n",
            "124          125             Pan de Hot Dog    Panadería Artesanal   \n",
            "125          126     Pan de Centeno Clásico       Panes Especiales   \n",
            "126          127        Quiche de espinacas       Bocadillo Salado   \n",
            "127          128              Ready Gen 107            Bebida Fría   \n",
            "128          129                Pan de Pita       Panes Especiales   \n",
            "129          130                  Croissant    Panadería Artesanal   \n",
            "130          131         Democratic Gen 150            Bebida Fría   \n",
            "131          132         Themselves Gen 125        Bebida Caliente   \n",
            "132          133       Crema de champiñones            Bebida Fría   \n",
            "133          134              Event Gen 184        Bebida Caliente   \n",
            "134          135                   Focaccia           Pan Integral   \n",
            "135          136                Way Gen 199        Bebida Caliente   \n",
            "136          137             Across Gen 155                 Postre   \n",
            "137          138              Shake Gen 110            Bebida Fría   \n",
            "138          139               Same Gen 128             Repostería   \n",
            "139          140          Authority Gen 159                 Postre   \n",
            "140          141             Second Gen 178                 Salado   \n",
            "141          142        Performance Gen 191                 Salado   \n",
            "142          143           Practice Gen 175             Repostería   \n",
            "143          144              Spend Gen 180            Bebida Fría   \n",
            "144          145             Citizen Gen 97             Repostería   \n",
            "145          146               Fruta fresca             Repostería   \n",
            "146          147      Guacamole con totopos            Bebida Fría   \n",
            "147          148            Arroz con leche                 Salado   \n",
            "148          149            Picture Gen 119                 Salado   \n",
            "149          150             Minute Gen 144        Bebida Caliente   \n",
            "150          151            Realize Gen 106                 Postre   \n",
            "151          152             Donut Glaseado                 Salado   \n",
            "152          153               Range Gen 87       Bocadillo Salado   \n",
            "153          154              Stuff Gen 124        Bebida Caliente   \n",
            "154          155               Grow Gen 131                 Postre   \n",
            "155          156               Over Gen 188                 Salado   \n",
            "156          157  Sándwich de Jamón y Queso                 Salado   \n",
            "157          158               Have Gen 169                 Postre   \n",
            "158          159                  Té helado        Bebida Caliente   \n",
            "159          160              Three Gen 157             Repostería   \n",
            "160          161               Life Gen 113                 Salado   \n",
            "161          162              Drive Gen 146             Repostería   \n",
            "162          163             Café Americano                 Postre   \n",
            "163          164             Relate Gen 132             Repostería   \n",
            "164          165               That Gen 172             Repostería   \n",
            "165          166            Another Gen 121            Bebida Fría   \n",
            "166          167               Light Gen 90                 Postre   \n",
            "167          168              Since Gen 173             Repostería   \n",
            "168          169                Pan Chapata           Pan Integral   \n",
            "169          170               Pan de Avena              Pan Dulce   \n",
            "170          171            Station Gen 109        Bebida Caliente   \n",
            "171          172         Pan de Tomate Seco                 Bollos   \n",
            "172          173               Down Gen 136                 Postre   \n",
            "173          174                Guy Gen 182                 Postre   \n",
            "174          175               Next Gen 123             Repostería   \n",
            "175          176             Center Gen 168             Repostería   \n",
            "176          177               Join Gen 167        Bebida Caliente   \n",
            "177          178               Your Gen 126            Bebida Fría   \n",
            "178          179            Chips de Patata                 Postre   \n",
            "179          180              Floor Gen 163             Repostería   \n",
            "180          181            Quality Gen 151                 Postre   \n",
            "181          182         Pan de Hamburguesa    Panadería Artesanal   \n",
            "182          183             Lawyer Gen 114                 Postre   \n",
            "183          184               Want Gen 187                 Postre   \n",
            "184          185            Usually Gen 100                 Salado   \n",
            "185          186                    Brioche                 Bollos   \n",
            "186          187              Wrap de Pollo       Bocadillo Salado   \n",
            "187          188           Sopa de tortilla                 Salado   \n",
            "188          189                Kid Gen 161            Bebida Fría   \n",
            "189          190           Daughter Gen 112            Bebida Fría   \n",
            "190          191              Along Gen 192        Bebida Caliente   \n",
            "191          192   Pan con Semillas de Chía                 Bollos   \n",
            "192          193         Helado de vainilla                 Salado   \n",
            "193          194               Dark Gen 195             Repostería   \n",
            "194          195              Carry Gen 105       Bocadillo Salado   \n",
            "195          196              Young Gen 103             Repostería   \n",
            "196          197             Prevent Gen 95             Repostería   \n",
            "197          198          Pan de Masa Madre    Panadería Artesanal   \n",
            "198          199             Zumo de frutas             Repostería   \n",
            "199          200           Pan de Aceitunas              Pan Dulce   \n",
            "\n",
            "     Precio_Base  \n",
            "0          12.13  \n",
            "1          37.93  \n",
            "2          26.91  \n",
            "3          24.47  \n",
            "4          40.16  \n",
            "5           4.39  \n",
            "6           6.38  \n",
            "7          20.39  \n",
            "8          15.30  \n",
            "9          19.35  \n",
            "10         18.32  \n",
            "11         38.65  \n",
            "12         19.08  \n",
            "13         15.99  \n",
            "14          3.39  \n",
            "15          1.68  \n",
            "16         39.00  \n",
            "17          4.10  \n",
            "18          8.87  \n",
            "19         43.17  \n",
            "20         29.19  \n",
            "21          9.74  \n",
            "22         43.99  \n",
            "23         36.53  \n",
            "24         32.73  \n",
            "25         30.31  \n",
            "26         48.84  \n",
            "27         18.24  \n",
            "28         17.83  \n",
            "29         23.59  \n",
            "30         31.62  \n",
            "31         13.88  \n",
            "32         24.90  \n",
            "33         22.18  \n",
            "34         35.17  \n",
            "35         38.76  \n",
            "36          8.39  \n",
            "37          2.26  \n",
            "38          5.09  \n",
            "39         46.48  \n",
            "40         28.43  \n",
            "41         44.08  \n",
            "42         35.70  \n",
            "43         19.74  \n",
            "44         18.99  \n",
            "45         19.57  \n",
            "46         10.96  \n",
            "47         40.63  \n",
            "48         23.00  \n",
            "49         19.17  \n",
            "50         12.44  \n",
            "51         27.47  \n",
            "52         31.35  \n",
            "53         44.39  \n",
            "54         43.85  \n",
            "55         49.05  \n",
            "56         13.49  \n",
            "57         30.58  \n",
            "58         22.32  \n",
            "59         25.87  \n",
            "60         14.56  \n",
            "61         49.79  \n",
            "62         29.60  \n",
            "63         47.00  \n",
            "64         28.22  \n",
            "65         39.30  \n",
            "66         41.63  \n",
            "67          5.37  \n",
            "68          3.72  \n",
            "69         17.60  \n",
            "70         22.43  \n",
            "71         36.30  \n",
            "72         40.29  \n",
            "73         22.31  \n",
            "74         27.69  \n",
            "75         48.29  \n",
            "76         13.09  \n",
            "77         45.29  \n",
            "78          3.18  \n",
            "79         36.28  \n",
            "80         21.26  \n",
            "81          7.92  \n",
            "82         11.29  \n",
            "83         29.19  \n",
            "84         23.28  \n",
            "85         37.81  \n",
            "86         29.73  \n",
            "87         39.78  \n",
            "88         10.01  \n",
            "89         21.47  \n",
            "90         13.02  \n",
            "91         19.37  \n",
            "92         21.54  \n",
            "93         27.38  \n",
            "94         34.38  \n",
            "95         34.46  \n",
            "96         29.93  \n",
            "97         43.18  \n",
            "98          1.75  \n",
            "99         10.01  \n",
            "100         3.51  \n",
            "101        29.32  \n",
            "102        37.64  \n",
            "103        40.58  \n",
            "104         8.32  \n",
            "105         5.59  \n",
            "106        28.07  \n",
            "107        33.04  \n",
            "108        44.26  \n",
            "109         8.11  \n",
            "110        16.54  \n",
            "111         7.04  \n",
            "112        19.62  \n",
            "113        33.55  \n",
            "114        48.87  \n",
            "115        13.46  \n",
            "116        20.93  \n",
            "117        40.97  \n",
            "118         1.09  \n",
            "119        41.84  \n",
            "120        41.68  \n",
            "121        24.29  \n",
            "122        49.48  \n",
            "123         2.55  \n",
            "124        42.22  \n",
            "125        16.82  \n",
            "126        12.07  \n",
            "127        26.74  \n",
            "128        37.20  \n",
            "129         9.65  \n",
            "130         6.43  \n",
            "131        17.22  \n",
            "132         3.47  \n",
            "133         5.08  \n",
            "134        47.81  \n",
            "135        47.03  \n",
            "136        46.35  \n",
            "137        26.28  \n",
            "138        20.36  \n",
            "139         5.88  \n",
            "140        30.02  \n",
            "141        17.52  \n",
            "142        31.78  \n",
            "143        49.46  \n",
            "144        43.55  \n",
            "145        49.21  \n",
            "146        22.44  \n",
            "147         3.05  \n",
            "148        19.04  \n",
            "149        31.67  \n",
            "150        33.79  \n",
            "151        17.57  \n",
            "152         2.18  \n",
            "153        11.38  \n",
            "154        11.61  \n",
            "155        22.63  \n",
            "156        19.81  \n",
            "157        29.39  \n",
            "158        20.65  \n",
            "159         6.99  \n",
            "160         8.38  \n",
            "161         5.56  \n",
            "162        32.50  \n",
            "163        22.86  \n",
            "164         7.31  \n",
            "165        19.61  \n",
            "166        17.07  \n",
            "167        17.92  \n",
            "168        11.45  \n",
            "169        21.20  \n",
            "170        28.14  \n",
            "171        41.77  \n",
            "172        45.46  \n",
            "173        18.30  \n",
            "174        40.66  \n",
            "175         1.25  \n",
            "176        23.81  \n",
            "177        23.85  \n",
            "178         6.25  \n",
            "179        30.13  \n",
            "180        31.62  \n",
            "181        32.95  \n",
            "182        22.31  \n",
            "183        41.09  \n",
            "184        11.49  \n",
            "185        23.65  \n",
            "186        21.68  \n",
            "187        10.99  \n",
            "188        48.67  \n",
            "189        16.04  \n",
            "190        39.58  \n",
            "191        44.24  \n",
            "192        44.05  \n",
            "193        46.94  \n",
            "194        34.83  \n",
            "195        24.28  \n",
            "196        32.57  \n",
            "197         7.72  \n",
            "198        22.49  \n",
            "199        26.23  . Creando dim_producto de demostración.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if 'Producto_ID' not in dim_producto.columns or 'Nombre_Producto' not in dim_producto.columns:\n",
        "    print(\"ERROR: DimProducto cargada no contiene las columnas 'Producto_ID' o 'Nombre_Producto' esperadas.\")\n",
        "    print(f\"Columnas actuales de dim_producto: {dim_producto.columns.tolist()}\")\n",
        "    raise KeyError(\"Columnas faltantes en DimProducto. No se puede realizar el merge.\")"
      ],
      "metadata": {
        "id": "p_3lOoXWv-Jz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_select = ['TransactionNo', 'DateTime', 'Items', 'Cantidad', 'Precio_Unitario', 'Total_Producto', 'Daypart', 'DayType']\n",
        "store_id_col = None\n",
        "\n",
        "if 'store_id' in df_final.columns:\n",
        "    cols_to_select.append('store_id')\n",
        "    store_id_col = 'store_id'\n",
        "elif 'ID_Tienda_Aleatoria' in df_final.columns:\n",
        "    cols_to_select.append('ID_Tienda_Aleatoria')\n",
        "    store_id_col = 'ID_Tienda_Aleatoria'\n",
        "else:\n",
        "    raise KeyError(\"Ni 'store_id' ni 'ID_Tienda_Aleatoria' encontrados en df_final_bronze. No se puede crear FactVentas.\")\n",
        "\n",
        "fact_ventas = df_final[cols_to_select].copy()\n",
        "\n",
        "# Renombrar la columna de ID de tienda a 'Tienda_ID'\n",
        "if store_id_col:\n",
        "    fact_ventas = fact_ventas.rename(columns={store_id_col: 'Tienda_ID'})\n",
        "print(\"  Columna de ID de tienda renombrada a 'Tienda_ID'.\")\n",
        "\n",
        "print(\"  DataFrame base de FactVentas creado:\")\n",
        "print(fact_ventas.head())\n",
        "print(\"-\" * 80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "KIESCfLD8J22",
        "outputId": "73bcb353-b6bb-4976-db8b-3fc1fc6a6de1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_final' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-981b40665b0f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstore_id_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;34m'store_id'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mcols_to_select\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'store_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mstore_id_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'store_id'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_final' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraer solo la parte de la fecha de 'DateTime' para la unión con DimFecha\n",
        "fact_ventas['Fecha_Completa_Solo_Fecha'] = fact_ventas['DateTime'].dt.normalize()\n",
        "\n",
        "fact_ventas = pd.merge(\n",
        "    fact_ventas,\n",
        "    dim_fecha[['Fecha_ID', 'Fecha_Completa']],\n",
        "    left_on='Fecha_Completa_Solo_Fecha',\n",
        "    right_on='Fecha_Completa',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Eliminar las columnas de unión temporales de fecha.\n",
        "# 'DateTime' se mantiene porque podría ser necesaria para otras uniones o en el final del Fact.\n",
        "fact_ventas = fact_ventas.drop(columns=['Fecha_Completa_Solo_Fecha', 'Fecha_Completa'])\n",
        "\n",
        "print(\"  'Fecha_ID' añadido a FactVentas.\")\n",
        "print(fact_ventas.head())\n",
        "print(\"-\" * 80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WgB6IN38WOR",
        "outputId": "4ea060f1-3fef-4b6d-d732-6e71b33807a0"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  'Fecha_ID' añadido a FactVentas.\n",
            "   TransactionNo            DateTime          Items  Cantidad  \\\n",
            "0              1 2016-10-30 09:58:11          Bread         1   \n",
            "1              2 2016-10-30 10:05:34   Scandinavian         3   \n",
            "2              2 2016-10-30 10:05:34   Scandinavian         4   \n",
            "3              3 2016-10-30 10:07:57  Hot chocolate         5   \n",
            "4              3 2016-10-30 10:07:57            Jam         5   \n",
            "\n",
            "   Precio_Unitario  Total_Producto  Daypart  DayType  Tienda_ID  Fecha_ID  \n",
            "0            17.77           17.77  Morning  Weekend        160  20161030  \n",
            "1            11.20           33.60  Morning  Weekend        153  20161030  \n",
            "2             6.10           24.40  Morning  Weekend        381  20161030  \n",
            "3             7.84           39.20  Morning  Weekend          2  20161030  \n",
            "4             1.09            5.45  Morning  Weekend        536  20161030  \n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"4. Uniendo con DimProducto para obtener 'Producto_ID'...\")\n",
        "\n",
        "if 'Producto_ID' not in dim_producto.columns or 'Nombre_Producto' not in dim_producto.columns:\n",
        "    print(\"ERROR: DimProducto cargada no contiene las columnas 'Producto_ID' o 'Nombre_Producto' esperadas.\")\n",
        "    print(f\"Columnas actuales de dim_producto: {dim_producto.columns.tolist()}\")\n",
        "    raise KeyError(\"Columnas faltantes en DimProducto. No se puede realizar el merge.\")\n",
        "\n",
        "fact_ventas = pd.merge(\n",
        "    fact_ventas,\n",
        "    dim_producto[['Producto_ID', 'Nombre_Producto']],\n",
        "    left_on='Items',  # 'Items' debe estar aquí para que el merge funcione\n",
        "    right_on='Nombre_Producto',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "if fact_ventas['Producto_ID'].isnull().any():\n",
        "    print(\"¡Advertencia! Algunos ítems en FactVentas no se encontraron en DimProducto (Producto_ID es NaN).\")\n",
        "    fact_ventas['Producto_ID'].fillna(0, inplace=True)\n",
        "\n",
        "# 'Items' y 'Nombre_Producto' se eliminan *después* de que se han usado en el merge\n",
        "fact_ventas = fact_ventas.drop(columns=['Items', 'Nombre_Producto'])\n",
        "\n",
        "print(\"  'Producto_ID' añadido a FactVentas.\")\n",
        "print(fact_ventas.head())\n",
        "print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUZHzgse8hAk",
        "outputId": "fa4cbafd-fa3c-42de-8407-c32ee77df3ee"
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4. Uniendo con DimProducto para obtener 'Producto_ID'...\n",
            "¡Advertencia! Algunos ítems en FactVentas no se encontraron en DimProducto (Producto_ID es NaN).\n",
            "  'Producto_ID' añadido a FactVentas.\n",
            "   TransactionNo            DateTime  Cantidad  Precio_Unitario  \\\n",
            "0              1 2016-10-30 09:58:11         1            17.77   \n",
            "1              2 2016-10-30 10:05:34         3            11.20   \n",
            "2              2 2016-10-30 10:05:34         4             6.10   \n",
            "3              3 2016-10-30 10:07:57         5             7.84   \n",
            "4              3 2016-10-30 10:07:57         5             1.09   \n",
            "\n",
            "   Total_Producto  Daypart  DayType  Tienda_ID  Fecha_ID  Producto_ID  \n",
            "0           17.77  Morning  Weekend        160  20161030          0.0  \n",
            "1           33.60  Morning  Weekend        153  20161030          0.0  \n",
            "2           24.40  Morning  Weekend        381  20161030          0.0  \n",
            "3           39.20  Morning  Weekend          2  20161030          0.0  \n",
            "4            5.45  Morning  Weekend        536  20161030          0.0  \n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-234-fdac6ef385d8>:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  fact_ventas['Producto_ID'].fillna(0, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"5. Procesando 'Tienda_ID' en FactVentas...\")\n",
        "# Este es el punto exacto donde la imagen_0e6b4c.png toma su captura.\n",
        "# La columna 'Tienda_ID' ya está presente en fact_ventas debido al renombramiento en la Parte 2.\n",
        "print(\"  'Tienda_ID' ya está presente en FactVentas y ha sido renombrada desde la fuente.\")\n",
        "print(fact_ventas.head()) # Este print genera la salida de la imagen_0e6b4c.png\n",
        "print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1mGVMEW6LRJ",
        "outputId": "c9798f5e-5fea-4d1a-e7b7-f26e1ba709bd"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5. Procesando 'Tienda_ID' en FactVentas...\n",
            "  'Tienda_ID' ya está presente en FactVentas y ha sido renombrada desde la fuente.\n",
            "   Id_Venta  Fecha_ID  Producto_ID  Tienda_ID  Cantidad_Vendida  \\\n",
            "0         1  20161030          0.0        160                 1   \n",
            "1         2  20161030          0.0        153                 3   \n",
            "2         2  20161030          0.0        381                 4   \n",
            "3         3  20161030          0.0          2                 5   \n",
            "4         3  20161030          0.0        536                 5   \n",
            "\n",
            "   Precio_Unitario_Venta  Total_Venta  Daypart  DayType  \n",
            "0                  17.77        17.77  Morning  Weekend  \n",
            "1                  11.20        33.60  Morning  Weekend  \n",
            "2                   6.10        24.40  Morning  Weekend  \n",
            "3                   7.84        39.20  Morning  Weekend  \n",
            "4                   1.09         5.45  Morning  Weekend  \n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"6. Renombrando columnas de medidas y seleccionando columnas finales para FactVentas...\")\n",
        "\n",
        "# Renombrar las columnas de medidas para que sean más descriptivas y estándar para un DW\n",
        "fact_ventas = fact_ventas.rename(columns={\n",
        "    'TransactionNo': 'Id_Venta',            # Clave primaria de la tabla de hechos\n",
        "    'Cantidad': 'Cantidad_Vendida',\n",
        "    'Precio_Unitario': 'Precio_Unitario_Venta',\n",
        "    'Total_Producto': 'Total_Venta'\n",
        "})\n",
        "\n",
        "# Seleccionar y reordenar las columnas finales para la tabla de hechos.\n",
        "# Asegúrate de incluir todas las claves foráneas (ID's de dimensiones) y las medidas.\n",
        "# La columna 'DateTime' puede mantenerse si la necesitas para análisis a nivel de tiempo,\n",
        "# o eliminarse si solo te interesa 'Fecha_ID'.\n",
        "fact_ventas = fact_ventas[[\n",
        "    'Id_Venta',              # Clave primaria/identificador de la venta\n",
        "    'Fecha_ID',              # Clave foránea a DimFecha\n",
        "    'Producto_ID',           # Clave foránea a DimProducto\n",
        "    'Tienda_ID',             # Clave foránea a DimTienda\n",
        "    'Cantidad_Vendida',      # Medida: Cantidad de artículos vendidos\n",
        "    'Precio_Unitario_Venta', # Medida: Precio unitario en el momento de la venta\n",
        "    'Total_Venta',           # Medida: Total de la venta por ítem\n",
        "    'Daypart',               # Atributo descriptivo (ej. 'Morning', 'Afternoon')\n",
        "    'DayType'                # Atributo descriptivo (ej. 'Weekday', 'Weekend')\n",
        "    # Puedes incluir 'DateTime' aquí si quieres mantener el timestamp original:\n",
        "    # 'DateTime'\n",
        "]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XG0rMeBB6TVA",
        "outputId": "b1855b4f-572d-447b-cf56-ae7f08d905fb"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6. Renombrando columnas de medidas y seleccionando columnas finales para FactVentas...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"  FactVentas final después de renombrar y seleccionar columnas:\")\n",
        "print(fact_ventas.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAiX6SNw6V2v",
        "outputId": "7b20e3af-d707-44f5-9b61-f89a17fc2769"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FactVentas final después de renombrar y seleccionar columnas:\n",
            "   Id_Venta  Fecha_ID  Producto_ID  Tienda_ID  Cantidad_Vendida  \\\n",
            "0         1  20161030          0.0        160                 1   \n",
            "1         2  20161030          0.0        153                 3   \n",
            "2         2  20161030          0.0        381                 4   \n",
            "3         3  20161030          0.0          2                 5   \n",
            "4         3  20161030          0.0        536                 5   \n",
            "\n",
            "   Precio_Unitario_Venta  Total_Venta  Daypart  DayType  \n",
            "0                  17.77        17.77  Morning  Weekend  \n",
            "1                  11.20        33.60  Morning  Weekend  \n",
            "2                   6.10        24.40  Morning  Weekend  \n",
            "3                   7.84        39.20  Morning  Weekend  \n",
            "4                   1.09         5.45  Morning  Weekend  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\nNúmero total de registros en FactVentas: {len(fact_ventas)}\")\n",
        "print(f\"Información de FactVentas (dtypes finales):\")\n",
        "print(fact_ventas.info())\n",
        "print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDuFXaOh6bIZ",
        "outputId": "2b5b57b9-eb54-4d9f-be5c-62e02fee0578"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Número total de registros en FactVentas: 20507\n",
            "Información de FactVentas (dtypes finales):\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20507 entries, 0 to 20506\n",
            "Data columns (total 9 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   Id_Venta               20507 non-null  int64  \n",
            " 1   Fecha_ID               20507 non-null  int64  \n",
            " 2   Producto_ID            20507 non-null  float64\n",
            " 3   Tienda_ID              20507 non-null  int64  \n",
            " 4   Cantidad_Vendida       20507 non-null  int64  \n",
            " 5   Precio_Unitario_Venta  20507 non-null  float64\n",
            " 6   Total_Venta            20507 non-null  float64\n",
            " 7   Daypart                20507 non-null  object \n",
            " 8   DayType                20507 non-null  object \n",
            "dtypes: float64(3), int64(4), object(2)\n",
            "memory usage: 1.4+ MB\n",
            "None\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define el nombre de tu archivo Parquet\n",
        "nombre_archivo4 = 'fact_ventas.parquet'\n",
        "full_path = os.path.join('/content/plata', nombre_archivo4)\n",
        "print(full_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt7AFK9h6uDA",
        "outputId": "33e821d2-da0d-489c-fda9-d0f709533391"
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/plata/fact_ventas.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guarda el DataFrame en formato Parquet\n",
        "# index=False es importante para no guardar el índice del DataFrame como una columna\n",
        "fact_ventas.to_parquet(full_path, index=False)\n",
        "\n",
        "print(f\"\\nDataFrame guardado exitosamente en la capa Plata como: {full_path}\")\n",
        "print(\"Puedes verificarlo en tu Google Drive en esa ruta.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qx0PRgN26vc5",
        "outputId": "fd973794-5beb-4cae-f6dd-b5a5719d833e"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame guardado exitosamente en la capa Plata como: /content/plata/fact_ventas.parquet\n",
            "Puedes verificarlo en tu Google Drive en esa ruta.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_leido4 = pd.read_parquet('/content/plata/fact_ventas.parquet')\n",
        "\n",
        "print(f\"\\nDataFrame leído :\")\n",
        "print(df_leido4.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1bnaD9D9fLi",
        "outputId": "fc6be37f-db55-4795-ef2c-623e68014cde"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame leído :\n",
            "   TransactionNo            DateTime  Cantidad  Precio_Unitario  \\\n",
            "0              1 2016-10-30 09:58:11         1            17.77   \n",
            "1              2 2016-10-30 10:05:34         3            11.20   \n",
            "2              2 2016-10-30 10:05:34         4             6.10   \n",
            "3              3 2016-10-30 10:07:57         5             7.84   \n",
            "4              3 2016-10-30 10:07:57         5             1.09   \n",
            "\n",
            "   Total_Producto  Daypart  DayType  Tienda_ID  Fecha_ID  Producto_ID  \n",
            "0           17.77  Morning  Weekend        160  20161030          0.0  \n",
            "1           33.60  Morning  Weekend        153  20161030          0.0  \n",
            "2           24.40  Morning  Weekend        381  20161030          0.0  \n",
            "3           39.20  Morning  Weekend          2  20161030          0.0  \n",
            "4            5.45  Morning  Weekend        536  20161030          0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##CAPA ORO"
      ],
      "metadata": {
        "id": "bFKjEhsTn5PS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('oro', exist_ok=True)\n",
        "fake = Faker()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hcnZXdHj1a14"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Ruta de la capa Plata: {'/content/plata'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0l-3znD-bGg",
        "outputId": "d3ea4ead-192e-48c1-9b5f-35e14401fae8"
      },
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ruta de la capa Plata: /content/plata\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Ruta de la capa Plata: {'/content/plata'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qq7Y7ExJ_Wfn",
        "outputId": "d8013d5d-401e-494f-e0c0-8b51b236d665"
      },
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ruta de la capa Plata: /content/plata\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np # Asegúrate de que esto esté si usas numpy\n",
        "import os\n",
        "try:\n",
        "    # Esta ruta '/content/plata' parece ser una ruta temporal local en Colab,\n",
        "    # no tu capa Silver en Google Drive. Asegúrate de que el archivo\n",
        "    # 'fact_ventas.parquet' realmente se haya guardado en '/content/plata'\n",
        "    # en un paso anterior.\n",
        "    fact_ventas_path = os.path.join('/content/plata', 'fact_ventas.parquet')\n",
        "    fact_ventas = pd.read_parquet(fact_ventas_path)\n",
        "    print(f\"FactVentas cargada. Filas: {len(fact_ventas)}. Columnas: {fact_ventas.columns.tolist()}\")\n",
        "    # Convertir 'Producto_ID' a int si se había rellenado con 0.0 (float)\n",
        "    if 'Producto_ID' in fact_ventas.columns and fact_ventas['Producto_ID'].dtype == 'float64':\n",
        "        fact_ventas['Producto_ID'] = fact_ventas['Producto_ID'].astype(int)\n",
        "    print(fact_ventas.head())\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: No se encontró 'fact_ventas.parquet' en {fact_ventas_path}. No se pueden generar reportes.\")\n",
        "    exit() # Salir si la tabla de hechos principal no está disponible\n",
        "except Exception as e:\n",
        "    print(f\"ERROR al cargar fact_ventas: {e}\")\n",
        "    exit()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WzN5lzy_i8a",
        "outputId": "fa6527a0-5029-4f9e-b22e-5b3430658165"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FactVentas cargada. Filas: 20507. Columnas: ['TransactionNo', 'DateTime', 'Cantidad', 'Precio_Unitario', 'Total_Producto', 'Daypart', 'DayType', 'Tienda_ID', 'Fecha_ID', 'Producto_ID']\n",
            "   TransactionNo            DateTime  Cantidad  Precio_Unitario  \\\n",
            "0              1 2016-10-30 09:58:11         1            17.77   \n",
            "1              2 2016-10-30 10:05:34         3            11.20   \n",
            "2              2 2016-10-30 10:05:34         4             6.10   \n",
            "3              3 2016-10-30 10:07:57         5             7.84   \n",
            "4              3 2016-10-30 10:07:57         5             1.09   \n",
            "\n",
            "   Total_Producto  Daypart  DayType  Tienda_ID  Fecha_ID  Producto_ID  \n",
            "0           17.77  Morning  Weekend        160  20161030            0  \n",
            "1           33.60  Morning  Weekend        153  20161030            0  \n",
            "2           24.40  Morning  Weekend        381  20161030            0  \n",
            "3           39.20  Morning  Weekend          2  20161030            0  \n",
            "4            5.45  Morning  Weekend        536  20161030            0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar las tablas de dimensión necesarias\n",
        "try:\n",
        "    dim_fecha_path = os.path.join('/content/plata', 'dimension_fecha_plata.parquet')\n",
        "    dim_fecha = pd.read_parquet(dim_fecha_path)\n",
        "    dim_fecha['Fecha_Completa'] = pd.to_datetime(dim_fecha['Fecha_Completa'])\n",
        "    # Asegúrate de tener las columnas 'Año' y 'Mes_Nombre' para el reporte mensual\n",
        "    if 'Mes_Nombre' not in dim_fecha.columns:\n",
        "        dim_fecha['Mes_Nombre'] = dim_fecha['Fecha_Completa'].dt.strftime('%B')\n",
        "    if 'Año' not in dim_fecha.columns:\n",
        "        dim_fecha['Año'] = dim_fecha['Fecha_Completa'].dt.year\n",
        "    print(f\"DimFecha cargada. Filas: {len(dim_fecha)}. Columnas: {dim_fecha.columns.tolist()}\")\n",
        "except Exception as e:\n",
        "    print(f\"ADVERTENCIA: No se pudo cargar DimFecha ({e}). Algunos reportes pueden verse afectados.\")\n",
        "    dim_fecha = pd.DataFrame({'Fecha_ID': [], 'Fecha_Completa': [], 'Mes_Nombre': [], 'Año': []}) # DataFrame vacío\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aogb8724BxHZ",
        "outputId": "9e3656d5-5b2f-4f9a-9e3d-ff40ea62d373"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DimFecha cargada. Filas: 694. Columnas: ['Fecha_ID', 'Fecha_Completa', 'Anio', 'Mes', 'Nombre_Mes', 'Dia', 'Dia_de_la_Semana', 'Nombre_Dia_Semana', 'Semana_del_Anio', 'Trimestre', 'Nombre_Trimestre', 'Es_Fin_De_Semana', 'Es_Dia_Laboral', 'Mes_Nombre', 'Año']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "try:\n",
        "    # La ruta real de tu archivo de dimensión producto (confirmada previamente como '/content/plata/dimension_producto_plata.parquet')\n",
        "    # O si la guardaste en tu silver_layer_path\n",
        "    dim_producto_path = os.path.join( '/content/plata'  , 'dimension_producto_plata.parquet')\n",
        "    # dim_producto_path = '/content/plata/dimension_producto_plata.parquet' # Usa esta si tu archivo está localmente en /content/plata/\n",
        "    df_temp_producto = pd.read_parquet(dim_producto_path)\n",
        "    # Renombrar columnas si es necesario al cargar\n",
        "    if 'product_id' in df_temp_producto.columns and 'product_name' in df_temp_producto.columns:\n",
        "        dim_producto = df_temp_producto.rename(columns={\n",
        "            'product_id': 'Producto_ID', 'product_name': 'Nombre_Producto',\n",
        "            'category': 'Clasificacion_Producto', 'price': 'Precio_Base'\n",
        "        })\n",
        "    elif 'Producto_ID' in df_temp_producto.columns and 'Nombre_Producto' in df_temp_producto.columns: # Caso esperado\n",
        "        dim_producto = df_temp_producto\n",
        "    else:\n",
        "        print(\"ADVERTENCIA: Columnas esperadas de DimProducto no encontradas en el archivo cargado. Usando un DataFrame vacío.\")\n",
        "        dim_producto = pd.DataFrame({'Producto_ID': [], 'Nombre_Producto': [], 'Clasificacion_Producto': [], 'Precio_Base': []})\n",
        "    print(f\"DimProducto cargada. Filas: {len(dim_producto)}. Columnas: {dim_producto.columns.tolist()}\")\n",
        "except Exception as e:\n",
        "    print(f\"ADVERTENCIA: No se pudo cargar DimProducto ({e}). Algunos reportes pueden verse afectados.\")\n",
        "    dim_producto = pd.DataFrame({'Producto_ID': [], 'Nombre_Producto': [], 'Clasificacion_Producto': [], 'Precio_Base': []}) # DataFrame vacío\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "ZOf7cc0SCRJy",
        "outputId": "f95f9379-ef0e-4ee8-ff0f-d8660d4f020c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ADVERTENCIA: No se pudo cargar DimProducto (name 'os' is not defined). Algunos reportes pueden verse afectados.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-214213101382>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# O si la guardaste en tu silver_layer_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdim_producto_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'/content/plata'\u001b[0m  \u001b[0;34m,\u001b[0m \u001b[0;34m'dimension_producto_plata.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# dim_producto_path = '/content/plata/dimension_producto_plata.parquet' # Usa esta si tu archivo está localmente en /content/plata/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-214213101382>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"ADVERTENCIA: No se pudo cargar DimProducto ({e}). Algunos reportes pueden verse afectados.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mdim_producto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Producto_ID'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Nombre_Producto'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Clasificacion_Producto'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Precio_Base'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# DataFrame vacío\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    dim_tienda_path = os.path.join(silver_layer_path, 'dim_tienda.parquet')\n",
        "    dim_tienda = pd.read_parquet(dim_tienda_path)\n",
        "    print(f\"DimTienda cargada. Filas: {len(dim_tienda)}. Columnas: {dim_tienda.columns.tolist()}\")\n",
        "except Exception as e:\n",
        "    print(f\"ADVERTENCIA: No se pudo cargar DimTienda ({e}). Algunos reportes pueden verse afectados.\")\n",
        "    dim_tienda = pd.DataFrame({'Tienda_ID': [], 'Nombre_Tienda': [], 'city': []}) # DataFrame vacío, incluir 'city'\n",
        "print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "48HUBsx_GbeT",
        "outputId": "ea51d49e-092c-4d5d-db0e-3faf6cba250d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ADVERTENCIA: No se pudo cargar DimTienda (name 'os' is not defined). Algunos reportes pueden verse afectados.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-2497ceb1e0e7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdim_tienda_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msilver_layer_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dim_tienda.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdim_tienda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim_tienda_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-2497ceb1e0e7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"ADVERTENCIA: No se pudo cargar DimTienda ({e}). Algunos reportes pueden verse afectados.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdim_tienda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Tienda_ID'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Nombre_Tienda'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'city'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# DataFrame vacío, incluir 'city'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Reporte: Total de ventas por mes ---\n",
        "print(\"1. Generando reporte 'Total de ventas por mes'...\")\n",
        "reporte_ventas_mes = fact_ventas.merge(\n",
        "    dim_fecha[['Fecha_ID', 'Año', 'Mes_Nombre']], # Usamos 'Año' y 'Mes_Nombre' de dim_fecha\n",
        "    on='Fecha_ID',\n",
        "    how='left'\n",
        ")\n",
        "reporte_ventas_mes_agg = reporte_ventas_mes.groupby(['Año', 'Mes_Nombre'])['Total_Venta'].sum().reset_index()"
      ],
      "metadata": {
        "id": "8oRr-BG_GobK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Opcional: Ordenar por año y un mes numérico si existe en dim_fecha\n",
        "reporte_ventas_mes_agg = reporte_ventas_mes_agg.sort_values(by=['Año', 'Mes_Nombre']) # Puede requerir un mapeo de Mes_Nombre a numérico para ordenar correctamente\n",
        "print(\"Reporte 'Total de ventas por mes':\")\n",
        "print(reporte_ventas_mes_agg.head())\n",
        "reporte_ventas_mes_agg.to_parquet(os.path.join(gold_layer_path, 'reporte_ventas_por_mes.parquet'), index=False)\n",
        "print(f\"Reporte guardado en: {os.path.join(gold_layer_path, 'reporte_ventas_por_mes.parquet')}\")\n",
        "print(\"-\" * 80)"
      ],
      "metadata": {
        "id": "14_q9EA8G2v7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Reporte: Ventas por ciudad ---\n",
        "print(\"2. Generando reporte 'Ventas por ciudad'...\")\n",
        "# Necesitamos la columna 'city' de dim_tienda.\n",
        "# df_final_bronze tenía 'city', así que asumo que dim_tienda también la tiene.\n",
        "if 'city' not in dim_tienda.columns:\n",
        "    print(\"ADVERTENCIA: La columna 'city' no se encontró en DimTienda. Generando datos de ciudad de ejemplo.\")\n",
        "    # Si 'city' no está en dim_tienda, la simulamos aquí\n",
        "    # Esto es una suposición para evitar que el código falle, pero lo ideal es que 'city' esté en tu dim_tienda\n",
        "    dim_tienda_temp = dim_tienda.copy()\n",
        "    num_unique_cities = 5\n",
        "    fake = Faker('es_ES')\n",
        "    cities = [fake.city() for _ in range(num_unique_cities)]\n",
        "    dim_tienda_temp['city'] = np.random.choice(cities, size=len(dim_tienda_temp))\n",
        "else:\n",
        "    dim_tienda_temp = dim_tienda.copy() # Usar la dim_tienda real si 'city' existe\n",
        "\n",
        "reporte_ventas_ciudad = fact_ventas.merge(\n",
        "    dim_tienda_temp[['Tienda_ID', 'city']],\n",
        "    on='Tienda_ID',\n",
        "    how='left'\n",
        ")\n",
        "reporte_ventas_ciudad_agg = reporte_ventas_ciudad.groupby('city')['Total_Venta'].sum().reset_index()\n",
        "reporte_ventas_ciudad_agg = reporte_ventas_ciudad_agg.sort_values(by='Total_Venta', ascending=False)"
      ],
      "metadata": {
        "id": "jGX6dWK0G4nB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Reporte 'Ventas por ciudad':\")\n",
        "print(reporte_ventas_ciudad_agg.head())\n",
        "reporte_ventas_ciudad_agg.to_parquet(os.path.join(gold_layer_path, 'reporte_ventas_por_ciudad.parquet'), index=False)\n",
        "print(f\"Reporte guardado en: {os.path.join(gold_layer_path, 'reporte_ventas_por_ciudad.parquet')}\")\n",
        "print(\"-\" * 80)\n"
      ],
      "metadata": {
        "id": "VEGGLmtmHBYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Reporte: Productos más vendidos (Top 10) ---\n",
        "print(\"3. Generando reporte 'Productos más vendidos (Top 10)'...\")\n",
        "reporte_productos_mas_vendidos = fact_ventas.merge(\n",
        "    dim_producto[['Producto_ID', 'Nombre_Producto']],\n",
        "    on='Producto_ID',\n",
        "    how='left'\n",
        ")\n",
        "reporte_productos_mas_vendidos_agg = reporte_productos_mas_vendidos.groupby('Nombre_Producto')['Cantidad_Vendida'].sum().reset_index()\n",
        "reporte_productos_mas_vendidos_agg = reporte_productos_mas_vendidos_agg.sort_values(by='Cantidad_Vendida', ascending=False).head(10)"
      ],
      "metadata": {
        "id": "haQ9njJXHHTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Reporte 'Productos más vendidos (Top 10)':\")\n",
        "print(reporte_productos_mas_vendidos_agg)\n",
        "reporte_productos_mas_vendidos_agg.to_parquet(os.path.join(gold_layer_path, 'reporte_top_10_productos.parquet'), index=False)\n",
        "print(f\"Reporte guardado en: {os.path.join(gold_layer_path, 'reporte_top_10_productos.parquet')}\")\n",
        "print(\"-\" * 80)"
      ],
      "metadata": {
        "id": "Fwl8z2ncHM-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Reporte: Tiendas que más venden (Top 10) ---\n",
        "print(\"4. Generando reporte 'Tiendas que más venden (Top 10)'...\")\n",
        "reporte_tiendas_mas_vendedoras = fact_ventas.merge(\n",
        "    dim_tienda[['Tienda_ID', 'Nombre_Tienda']],\n",
        "    on='Tienda_ID',\n",
        "    how='left'\n",
        ")\n",
        "reporte_tiendas_mas_vendedoras_agg = reporte_tiendas_mas_vendedoras.groupby('Nombre_Tienda')['Total_Venta'].sum().reset_index()\n",
        "reporte_tiendas_mas_vendedoras_agg = reporte_tiendas_mas_vendedoras_agg.sort_values(by='Total_Venta', ascending=False).head(10)"
      ],
      "metadata": {
        "id": "9x5HDKWDHQ6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Reporte 'Tiendas que más venden (Top 10)':\")\n",
        "print(reporte_tiendas_mas_vendedoras_agg)\n",
        "reporte_tiendas_mas_vendedoras_agg.to_parquet(os.path.join(gold_layer_path, 'reporte_top_10_tiendas.parquet'), index=False)\n",
        "print(f\"Reporte guardado en: {os.path.join(gold_layer_path, 'reporte_top_10_tiendas.parquet')}\")\n",
        "print(\"-\" * 80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "M6YG2qBJHXuT",
        "outputId": "e7c1bc69-7f2e-453f-f591-e1ed49eaf864"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reporte 'Tiendas que más venden (Top 10)':\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'reporte_tiendas_mas_vendedoras_agg' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-85f79e7d586f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reporte 'Tiendas que más venden (Top 10)':\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreporte_tiendas_mas_vendedoras_agg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mreporte_tiendas_mas_vendedoras_agg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold_layer_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reporte_top_10_tiendas.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Reporte guardado en: {os.path.join(gold_layer_path, 'reporte_top_10_tiendas.parquet')}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'reporte_tiendas_mas_vendedoras_agg' is not defined"
          ]
        }
      ]
    }
  ]
}